"""Main entrypoint for HEAN system."""

import argparse
import asyncio
import signal
import sys
import uuid
from collections import OrderedDict
from datetime import datetime, timedelta
from typing import Any, Literal

from hean.agent_generation.capital_optimizer import CapitalOptimizer
from hean.agent_generation.catalyst import ImprovementCatalyst
from hean.agent_generation.report_generator import ReportGenerator
from hean.backtest.event_sim import EventSimulator
from hean.backtest.metrics import BacktestMetrics
from hean.config import settings
from hean.core.arb.triangular_scanner import TriangularScanner
from hean.core.bus import EventBus
from hean.core.clock import Clock
from hean.core.fabric import CausalRegistry, EEVScorer, EventDNA, extract_dna, inject_dna
from hean.core.intelligence.correlation_engine import CorrelationEngine
from hean.core.multi_symbol_scanner import MultiSymbolScanner
from hean.core.regime import Regime, RegimeDetector
from hean.core.telemetry.self_insight import SelfInsightCollector
from hean.core.timeframes import CandleAggregator
from hean.core.trade_density import trade_density
from hean.core.types import (
    Event,
    EventType,
    Order,
    OrderRequest,
    OrderStatus,
    Position,
    RiskEnvelope,
    Signal,
    Tick,
)
from hean.evaluation.truth_layer import analyze_truth, print_truth
from hean.exchange.models import PriceFeed
from hean.execution.order_manager import OrderManager
from hean.execution.position_monitor import PositionMonitor
from hean.execution.position_reconciliation import PositionReconciler
from hean.execution.router import ExecutionRouter
from hean.income.streams import (
    BasisHedgeStream,
    FundingHarvesterStream,
    MakerRebateStream,
    VolatilityHarvestStream,
)
from hean.logging import get_logger, setup_logging
from hean.observability.health import HealthCheck
from hean.observability.metrics import metrics
from hean.observability.monitoring.self_healing import SelfHealingMiddleware
from hean.observability.no_trade_report import no_trade_report
from hean.paper_trade_assist import (
    is_paper_assist_enabled,
    log_allow_reason,
    log_block_reason,
)
from hean.portfolio.accounting import PortfolioAccounting
from hean.portfolio.allocator import CapitalAllocator
from hean.portfolio.decision_memory import DecisionMemory
from hean.portfolio.profit_capture import ProfitCapture
from hean.portfolio.profit_target_tracker import ProfitTargetTracker
from hean.portfolio.smart_reinvestor import SmartReinvestor
from hean.risk.capital_preservation import CapitalPreservationMode
from hean.risk.deposit_protector import DepositProtector
from hean.risk.killswitch import KillSwitch
from hean.risk.limits import RiskLimits
from hean.risk.multi_level_protection import MultiLevelProtection
from hean.risk.position_sizer import PositionSizer
from hean.risk.tail_risk import GlobalSafetyNet
from hean.strategies.base import BaseStrategy
from hean.strategies.basis_arbitrage import BasisArbitrage
from hean.strategies.correlation_arb import CorrelationArbitrage
from hean.strategies.enhanced_grid import EnhancedGridStrategy
from hean.strategies.funding_harvester import FundingHarvester
from hean.strategies.hf_scalping import HFScalpingStrategy
from hean.strategies.impulse_engine import ImpulseEngine
from hean.strategies.inventory_neutral_mm import InventoryNeutralMM
from hean.strategies.liquidity_sweep import LiquiditySweepDetector
from hean.strategies.momentum_trader import MomentumTrader
from hean.strategies.rebate_farmer import RebateFarmer
from hean.strategies.sentiment_strategy import SentimentStrategy

logger = get_logger(__name__)


class TradingSystem:
    """Main trading system orchestrator."""

    def __init__(
        self,
        mode: Literal["run", "evaluate"] = "run",
        bus: EventBus | None = None,
    ) -> None:
        """Initialize the trading system.

        Args:
            mode: Operation mode. "run" for live/paper trading, "evaluate" for evaluation.
                  In evaluate mode, HealthCheck is disabled and periodic status is skipped.
            bus: Optional shared EventBus instance for external subscribers.
        """
        self._mode = mode
        self._bus = bus or EventBus()
        self._clock = Clock()

        # Use backtest capital in evaluate mode
        initial_capital = (
            settings.backtest_initial_capital if mode == "evaluate" else settings.initial_capital
        )
        self._accounting = PortfolioAccounting(initial_capital)

        # Deposit protection and profit tracking
        self._deposit_protector = DepositProtector(self._bus, initial_capital)
        self._profit_tracker = ProfitTargetTracker()
        self._profit_capture = ProfitCapture(self._bus, initial_capital)

        self._allocator = CapitalAllocator()
        self._decision_memory = DecisionMemory()
        self._risk_limits = RiskLimits()
        self._position_sizer = PositionSizer()
        self._killswitch = KillSwitch(self._bus)
        self._order_manager = OrderManager()
        self._regime_detector = RegimeDetector(self._bus)
        self._execution_router = ExecutionRouter(
            self._bus, self._order_manager, self._regime_detector
        )
        # Position Monitor - force-closes stale positions
        self._position_monitor = PositionMonitor(self._bus, self._accounting)
        # Position Reconciler - ensures local state matches exchange (initialized in run())
        self._position_reconciler: PositionReconciler | None = None
        self._multi_symbol_scanner = MultiSymbolScanner(self._bus)
        self._price_feed: PriceFeed | None = None
        self._strategies: list = []
        self._income_streams: list = []
        self._candle_aggregator: CandleAggregator | None = None

        # Context aggregator (fuses Brain+Physics+TCN+OFI+Causal ‚Üí CONTEXT_READY)
        self._context_aggregator = None
        self._microservices_bridge = None

        # Risk-First architecture: RiskSentinel + IntelligenceGate
        self._risk_sentinel: Any = None
        self._intelligence_gate: Any = None
        self._self_insight_collector: SelfInsightCollector | None = None

        # Auto-improvement systems
        self._improvement_catalyst: ImprovementCatalyst | None = None
        self._ai_factory = None
        self._capital_optimizer = CapitalOptimizer()
        self._report_generator = ReportGenerator()

        # AI Council (multi-model periodic system review)
        self._council = None
        # Trade Council 2.0 (real-time adversarial signal evaluation)
        self._trade_council = None

        # AutoPilot Coordinator (meta-brain for autonomous self-improvement)
        self._autopilot = None

        # Temporal Event Fabric (causal DNA + EEV scoring)
        self._fabric_registry: CausalRegistry | None = None
        self._fabric_eev: EEVScorer | None = None
        self._fabric_tick_dna: dict[str, EventDNA] = {}  # symbol ‚Üí last TICK DNA

        # ARCHON ‚Äî Brain-Orchestrator
        self._archon: Any = None  # TYPE_CHECKING import to avoid circular dependency

        # Phase 5: Statistical Arbitrage & Anti-Fragile Architecture
        self._correlation_engine: CorrelationEngine | None = None
        self._safety_net: GlobalSafetyNet | None = None
        self._self_healing: SelfHealingMiddleware | None = None

        # Skip HealthCheck in evaluate mode
        self._health_check = HealthCheck() if mode == "run" else None

        self._running = False
        self._stop_trading = False
        self._current_regime: dict[str, Regime] = {}

        # Paper trade assist: fallback micro-trade tracking
        self._last_micro_trade_time: dict[str, datetime] = {}
        self._micro_trade_task: asyncio.Task[None] | None = None
        self._impulse_engine: ImpulseEngine | None = None
        self._triangular_scanner: TriangularScanner | None = None

        # Physics engine components
        self._physics_engine = None
        self._participant_classifier = None
        self._anomaly_detector = None
        self._temporal_stack = None
        self._cross_market = None

        # SovereignSymbiont ‚Äî Phase 3 live wiring (optional)
        self._sovereign_symbiont: Any = None

        # Digital Organism components
        self._market_genome_detector = None
        self._doomsday_sandbox = None
        self._meta_strategy_brain = None
        self._evolution_bridge = None

        # Debug metrics for forced order flow
        self._signals_generated = 0
        self._signals_after_filters = 0
        self._orders_sent = 0
        self._orders_filled = 0
        self._order_decision_history: list[dict[str, Any]] = []
        self._order_exit_decision_history: list[dict[str, Any]] = []

        # Exit management / heartbeat tracking
        self._last_exit_decision_ts: dict[str, datetime] = {}
        self._last_tick_at: dict[str, datetime] = {}

    async def _emit_order_decision(
        self,
        signal: Signal,
        decision: str,
        reason_code: str,
        computed_qty: float | None,
        context: dict[str, Any],
    ) -> None:
        """Emit structured order decision telemetry for observability.

        Includes gating flags, reason_codes array, market_regime, and advisory fields per AFO-Director spec.
        """
        # Collect gating flags for diagnostics
        equity = self._accounting.get_equity()
        drawdown_amount, drawdown_pct = self._accounting.get_drawdown(equity)
        open_positions = len(self._accounting.get_positions())
        open_orders = len(self._order_manager.get_open_orders())

        # Build reason_codes array (reason_code + any additional reasons from context)
        reason_codes = [reason_code]
        if "additional_reasons" in context:
            reason_codes.extend(context["additional_reasons"])

        # Get current regime for symbol
        market_regime = None
        market_metrics_short = {}
        if hasattr(self, "_regime_detector"):
            current_regime = self._regime_detector.get_regime(signal.symbol) if hasattr(self._regime_detector, "get_regime") else None
            if current_regime:
                # Map existing regime to spec regime types
                regime_map = {
                    "impulse": "TREND",
                    "normal": "RANGE",
                    "range": "RANGE",
                }
                market_regime = regime_map.get(current_regime.value if hasattr(current_regime, "value") else str(current_regime), "RANGE")

        # Check for stale data
        last_tick_age_sec = None
        if hasattr(self, "_last_tick_at") and signal.symbol in self._last_tick_at:
            last_tick_age_sec = (datetime.utcnow() - self._last_tick_at[signal.symbol]).total_seconds()
            if last_tick_age_sec > 30:
                market_regime = "STALE_DATA"
                reason_codes.append("STALE_MARKET_DATA")

        # Check liquidity (simple heuristic: if spread is too wide, mark as LOW_LIQ)
        if hasattr(self, "_execution_router") and hasattr(self._execution_router, "_current_bids") and hasattr(self._execution_router, "_current_asks"):
            bid = self._execution_router._current_bids.get(signal.symbol)
            ask = self._execution_router._current_asks.get(signal.symbol)
            if bid and ask and bid > 0:
                spread_pct = ((ask - bid) / bid) * 100
                market_metrics_short["spread_pct"] = spread_pct
                if spread_pct > 0.5:  # 0.5% spread threshold
                    if market_regime != "STALE_DATA":
                        market_regime = "LOW_LIQ"
                    reason_codes.append("LOW_LIQUIDITY")

        # Build comprehensive gating flags
        gating_flags = {
            "risk_ok": not self._stop_trading and not (self._killswitch.is_triggered() if hasattr(self, "_killswitch") else False),
            "data_fresh_ok": last_tick_age_sec is None or last_tick_age_sec < 30,
            "profit_lock_ok": True,  # Will be set by profit capture in B2
            "engine_running_ok": not self._stop_trading,
            "symbol_enabled_ok": signal.symbol in (settings.trading_symbols if hasattr(settings, "trading_symbols") else []),
            "liquidity_ok": market_regime != "LOW_LIQ",
            "execution_ok": True,  # Will be enhanced by execution quality checks
            "stop_trading": self._stop_trading,
            "killswitch_triggered": self._killswitch.is_triggered() if hasattr(self, "_killswitch") else False,
            "max_positions": open_positions >= settings.max_open_positions,
            "max_orders": open_orders >= settings.max_open_orders,
            "drawdown_pct": drawdown_pct,
            "equity": equity,
        }

        # Add killswitch reason if triggered
        if gating_flags["killswitch_triggered"] and hasattr(self, "_killswitch"):
            gating_flags["killswitch_reason"] = self._killswitch.get_reason()

        # Build advisory (how to continue)
        advisory = None
        if decision in ("SKIP", "BLOCK"):
            hints = []
            how_to_continue = None

            if not gating_flags["risk_ok"]:
                if gating_flags["killswitch_triggered"]:
                    how_to_continue = "check_killswitch"
                    hints.append("Review killswitch reasons and thresholds")
                elif self._stop_trading:
                    how_to_continue = "resume"
                    hints.append("Resume trading if conditions are safe")
            elif not gating_flags["data_fresh_ok"]:
                how_to_continue = "check_data_feed"
                hints.append("Verify market data connection")
            elif not gating_flags["liquidity_ok"]:
                how_to_continue = "wait_for_liquidity"
                hints.append("Wait for better liquidity conditions")
            elif gating_flags["max_positions"] or gating_flags["max_orders"]:
                how_to_continue = "reduce_positions"
                hints.append("Close some positions or orders to free capacity")
            elif drawdown_pct > 10:
                how_to_continue = "reduce_risk"
                hints.append("Reduce risk exposure due to drawdown")
            else:
                how_to_continue = "resume"
                hints.append("System should resume automatically")

            advisory = {
                "how_to_continue": how_to_continue,
                "hints": hints,
            }

        # Get score/confidence from context if available
        score = context.get("score") or context.get("confidence")

        payload = {
            "type": "ORDER_DECISION",
            "decision": decision,  # CREATE|SKIP|BLOCK
            "reason_codes": reason_codes,  # Array of reason codes
            "reason_code": reason_code,  # Keep for backward compatibility
            "signal_id": signal.strategy_id + ":" + signal.symbol + ":" + signal.side,
            "strategy_id": signal.strategy_id,
            "symbol": signal.symbol,
            "side": signal.side,
            "timestamp": datetime.utcnow().isoformat(),
            "computed_qty": computed_qty,
            "gating_flags": gating_flags,
            "score": score,  # nullable
            "confidence": score,  # nullable, alias
            "market_regime": market_regime,  # TREND|RANGE|LOW_LIQ|STALE_DATA
            "market_metrics_short": market_metrics_short,  # spread_pct, etc.
            "advisory": advisory,  # nullable
            **{k: v for k, v in context.items() if k not in ("additional_reasons", "score", "confidence")},
        }
        # Keep short history for diagnostics
        self._order_decision_history.append(payload)
        self._order_decision_history = self._order_decision_history[-100:]
        logger.info(f"[ORDER_DECISION] {payload}")
        try:
            await self._bus.publish(
                Event(event_type=EventType.ORDER_DECISION, data=payload)
            )
        except Exception as e:
            logger.debug(f"Failed to publish ORDER_DECISION event: {e}")

    async def _emit_order_exit_decision(
        self,
        position: Position,
        decision: str,
        reason_code: str,
        tick_price: float | None,
        thresholds: dict[str, Any],
        hold_seconds: float | None = None,
        note: str | None = None,
    ) -> None:
        """Emit structured exit decision telemetry (TP/SL/TTL/HOLD)."""
        payload = {
            "type": "ORDER_EXIT_DECISION",
            "decision": decision,
            "reason_code": reason_code,
            "position_id": position.position_id,
            "order_id": position.metadata.get("entry_order_id") if position.metadata else None,
            "symbol": position.symbol,
            "side": position.side,
            "timestamp": datetime.utcnow().isoformat(),
            "last_price": tick_price,
            "entry_price": position.entry_price,
            "unrealized_pnl": position.unrealized_pnl,
            "realized_pnl": position.realized_pnl,
            "qty": position.size,
            "strategy_id": position.strategy_id,
            "hold_seconds": hold_seconds,
            "thresholds": thresholds,
            "metadata": position.metadata or {},
        }
        if note:
            payload["note"] = note

        self._order_exit_decision_history.append(payload)
        self._order_exit_decision_history = self._order_exit_decision_history[-200:]
        self._last_exit_decision_ts[position.position_id] = datetime.utcnow()
        logger.info(f"[ORDER_EXIT_DECISION] {payload}")
        try:
            await self._bus.publish(
                Event(event_type=EventType.ORDER_EXIT_DECISION, data=payload)
            )
        except Exception as e:
            logger.debug(f"Failed to publish ORDER_EXIT_DECISION event: {e}")

    async def start(self, price_feed=None) -> None:
        """Start the trading system.

        Args:
            price_feed: Optional PriceFeed instance to inject. If provided, uses this
                       instead of creating BybitPriceFeed. Used for evaluation mode
                       with EventSimulator.
        """
        logger.info("Starting HEAN trading system...")
        logger.info(f"Trading mode: {settings.trading_mode}")
        logger.info(f"DRY_RUN: {settings.dry_run}")
        logger.info(f"bybit_testnet: {settings.bybit_testnet}")
        logger.info(f"PAPER_TRADE_ASSIST: {settings.paper_trade_assist}")
        logger.info(f"LIVE_CONFIRM: {settings.live_confirm}")

        # Use initial capital from config (balance sync disabled to prevent hangs)
        initial_capital = (
            settings.backtest_initial_capital
            if self._mode == "evaluate"
            else settings.initial_capital
        )
        logger.info(f"Using configured capital: ${initial_capital:.2f}")

        logger.info(f"Initial capital: ${initial_capital:,.2f}")
        logger.info(f"Profit target: ${settings.profit_target_daily_usd:.2f}/day")
        logger.info(
            f"Deposit protection: {'ENABLED' if settings.deposit_protection_active else 'DISABLED'}"
        )
        logger.info(f"DRY_RUN: {settings.dry_run}")
        logger.info(f"PROCESS_FACTORY_ENABLED: {settings.process_factory_enabled}")
        logger.info(f"PROCESS_FACTORY_ALLOW_ACTIONS: {settings.process_factory_allow_actions}")
        logger.info(f"EXECUTION_SMOKE_TEST_ENABLED: {settings.execution_smoke_test_enabled}")

        use_redis_physics = self._mode == "run" and settings.physics_source == "redis"
        use_redis_brain = self._mode == "run" and settings.brain_source == "redis"
        use_redis_risk = self._mode == "run" and settings.risk_source == "redis"

        # Start core components
        await self._bus.start()
        await self._clock.start()
        await self._execution_router.start()
        # Start multi-timeframe candle aggregation
        self._candle_aggregator = CandleAggregator(self._bus)
        await self._candle_aggregator.start()

        # Start Position Monitor - force-closes stale positions
        await self._position_monitor.start()
        logger.info(f"Position Monitor started (max_hold={settings.max_hold_seconds}s)")

        # Start Position Reconciler - ensures local state matches exchange
        # Only in run mode (not evaluate mode) and if execution router has bybit_http
        if self._mode == "run" and hasattr(self._execution_router, "_bybit_http"):
            try:
                self._position_reconciler = PositionReconciler(
                    bus=self._bus,
                    bybit_http=self._execution_router._bybit_http,
                    accounting=self._accounting,
                )
                await self._position_reconciler.start()
                logger.info("Position Reconciler started (30s interval)")
            except Exception as e:
                logger.warning(f"Position Reconciler failed to start: {e}")

        # Only start HealthCheck in run mode
        if self._health_check:
            await self._health_check.start()

        # Self-insight collector
        if getattr(settings, "self_insight_enabled", True):
            self._self_insight_collector = SelfInsightCollector(
                self._bus,
                publish_interval=getattr(settings, "self_insight_interval", 60),
            )
            await self._self_insight_collector.start()

        # Start regime detector
        await self._regime_detector.start()
        self._bus.subscribe(EventType.REGIME_UPDATE, self._handle_regime_update)

        # Start multi-symbol scanner
        await self._multi_symbol_scanner.start()

        # Phase: Oracle Engine Integration (Algorithmic Fingerprinting + TCN)
        if self._mode == "run" and getattr(settings, 'oracle_engine_enabled', True):
            try:
                from hean.core.intelligence.oracle_integration import OracleIntegration
                self._oracle_integration = OracleIntegration(self._bus, symbols=settings.trading_symbols)
                await self._oracle_integration.start()
                logger.info("Oracle Engine Integration started (Fingerprinting + TCN)")
            except ModuleNotFoundError as e:
                logger.warning(f"Oracle Engine disabled (missing dependency): {e}")
            except Exception as e:
                logger.warning(f"Oracle Engine failed to start: {e}")

        # Phase 5: Initialize Statistical Arbitrage & Anti-Fragile Architecture
        if self._mode == "run" and settings.phase5_correlation_engine_enabled:
            # 1. Correlation Engine for pair trading
            self._correlation_engine = CorrelationEngine(self._bus, symbols=settings.trading_symbols)
            await self._correlation_engine.start()
            logger.info("Phase 5: Correlation Engine started")

        if self._mode == "run" and settings.phase5_safety_net_enabled:
            # 2. Global Safety Net (Black Swan Protection)
            self._safety_net = GlobalSafetyNet(
                bus=self._bus,
                regime_detector=self._regime_detector,
                accounting=self._accounting,
                position_sizer=self._position_sizer
            )
            await self._safety_net.start()
            logger.info("Phase 5: Global Safety Net activated")

        if self._mode == "run" and settings.phase5_self_healing_enabled:
            # 3. Self-Healing Middleware
            self._self_healing = SelfHealingMiddleware(
                bus=self._bus,
                order_manager=self._order_manager
            )
            await self._self_healing.start()
            logger.info("Phase 5: Self-Healing Middleware started")

        if self._mode == "run" and settings.phase5_kelly_criterion_enabled:
            # 4. Enable Kelly Criterion for Position Sizer
            try:
                if hasattr(self._position_sizer, 'enable_kelly_criterion'):
                    self._position_sizer.enable_kelly_criterion(
                        self._accounting,
                        fractional_kelly=settings.phase5_kelly_fractional
                    )
                    logger.info(f"Phase 5: Kelly Criterion enabled with fractional_kelly={settings.phase5_kelly_fractional}")
            except Exception as e:
                logger.warning(f"Could not enable Kelly Criterion: {e}")

        # Physics Engine: Market thermodynamics
        if self._mode == "run" and not use_redis_physics:
            try:
                from hean.physics import (
                    CrossMarketImpulse,
                    MarketAnomalyDetector,
                    ParticipantClassifier,
                    PhysicsEngine,
                    TemporalStack,
                )

                self._physics_engine = PhysicsEngine(bus=self._bus)
                await self._physics_engine.start()

                self._participant_classifier = ParticipantClassifier(bus=self._bus)
                await self._participant_classifier.start()

                self._anomaly_detector = MarketAnomalyDetector()

                self._temporal_stack = TemporalStack(symbols=settings.trading_symbols)

                self._cross_market = CrossMarketImpulse(
                    leader_symbols=[settings.cross_market_leader],
                    follower_symbols=settings.cross_market_followers,
                )

                logger.info("Physics Engine started (Temperature/Entropy/Phase/Participants/Anomalies/TemporalStack)")
            except Exception as e:
                logger.warning(f"Physics Engine failed to start: {e}")
        elif self._mode == "run":
            logger.info("Physics source=redis, skipping in-process PhysicsEngine")

        # Brain: AI market analysis (SovereignBrain or ClaudeBrainClient)
        # Selection logic:
        #   1. sovereign_brain_enabled=True ‚Üí always SovereignBrain
        #   2. groq/deepseek/openrouter/ollama key present AND no anthropic key ‚Üí SovereignBrain
        #   3. anthropic_api_key present ‚Üí ClaudeBrainClient (legacy)
        #   4. nothing ‚Üí skip brain
        self._brain_client = None
        if self._mode == "run" and getattr(settings, 'brain_enabled', True) and not use_redis_brain:
            try:
                use_sovereign = bool(getattr(settings, 'sovereign_brain_enabled', False))
                has_sovereign_providers = bool(
                    getattr(settings, 'groq_api_key', '')
                    or getattr(settings, 'deepseek_api_key', '')
                    or getattr(settings, 'openrouter_api_key', '')
                    or getattr(settings, 'ollama_enabled', False)
                )
                anthropic_key = str(getattr(settings, 'anthropic_api_key', '') or '')

                if use_sovereign or (has_sovereign_providers and not anthropic_key):
                    try:
                        from hean.brain.sovereign_brain import SovereignBrain

                        self._brain_client = SovereignBrain(bus=self._bus, settings=settings)
                        await self._brain_client.start()
                        providers = getattr(self._brain_client, 'active_providers', [])
                        logger.info("SovereignBrain started (independent) | providers=%s", providers)
                    except ImportError as imp_err:
                        logger.warning("SovereignBrain not available (%s) ‚Äî falling back to ClaudeBrainClient", imp_err)
                        from hean.brain.claude_client import ClaudeBrainClient
                        self._brain_client = ClaudeBrainClient(
                            bus=self._bus,
                            api_key=anthropic_key,
                            analysis_interval=getattr(settings, 'brain_analysis_interval', 60),
                            openrouter_api_key=getattr(settings, 'openrouter_api_key', ''),
                        )
                        await self._brain_client.start()
                        logger.info("Brain Client started (ClaudeBrainClient fallback)")
                else:
                    from hean.brain.claude_client import ClaudeBrainClient
                    self._brain_client = ClaudeBrainClient(
                        bus=self._bus,
                        api_key=anthropic_key,
                        analysis_interval=getattr(settings, 'brain_analysis_interval', 60),
                        openrouter_api_key=getattr(settings, 'openrouter_api_key', ''),
                    )
                    await self._brain_client.start()
                    logger.info("Brain Client started (ClaudeBrainClient)")
            except Exception as e:
                logger.warning("Brain Client failed to start: %s", e)
        elif self._mode == "run" and use_redis_brain:
            logger.info("Brain source=redis, skipping in-process Brain Client")

        # ContextAggregator: fuses Brain+Physics+TCN+OFI+Causal ‚Üí CONTEXT_READY
        if self._mode == "run":
            try:
                from hean.core.context_aggregator import ContextAggregator

                symbols_for_context = settings.symbols if settings.multi_symbol_enabled else settings.trading_symbols
                self._context_aggregator = ContextAggregator(self._bus, symbols_for_context)
                await self._context_aggregator.start()
                logger.info("ContextAggregator started")
            except Exception as e:
                logger.warning(f"ContextAggregator failed to start: {e}")

        # AI Factory: Shadow ‚Üí Canary ‚Üí Production pipeline
        if self._mode == "run":
            try:
                from hean.ai.factory import AIFactory

                self._ai_factory = AIFactory(self._bus)
                logger.info("AI Factory initialized")
            except Exception as e:
                logger.warning(f"AI Factory failed to initialize: {e}")

        # DuckDB Storage (optional)
        self._duckdb_store = None
        if self._mode == "run":
            try:
                from hean.storage.duckdb_store import DuckDBStore

                self._duckdb_store = DuckDBStore(bus=self._bus)
                await self._duckdb_store.start()
                logger.info("DuckDB Storage started")
            except ImportError:
                logger.info("DuckDB not installed, storage disabled")
            except Exception as e:
                logger.warning(f"DuckDB Storage failed to start: {e}")

        # Start price feed
        # Use multi-symbol list if MULTI_SYMBOL_ENABLED, otherwise use trading_symbols
        if settings.multi_symbol_enabled:
            symbols = settings.symbols
            logger.info(f"Multi-Symbol Mode ENABLED: trading {len(symbols)} symbols: {symbols}")
        else:
            symbols = settings.trading_symbols
            logger.info(f"Single/Limited Symbol Mode: trading {len(symbols)} symbols: {symbols}")
        if price_feed is not None:
            # Use injected price feed (e.g., EventSimulator for evaluation)
            self._price_feed = price_feed
            # EventSimulator needs bus injected via start()
            if isinstance(price_feed, EventSimulator):
                await price_feed.start(bus=self._bus)
            else:
                await price_feed.start()
        elif settings.is_live or settings.paper_use_live_feed:
            # Use Bybit price feed for live or paper mode (public data)
            try:
                from hean.exchange.bybit.price_feed import BybitPriceFeed

                self._price_feed = BybitPriceFeed(self._bus, symbols)
                await self._price_feed.start()
                mode_label = "live" if settings.is_live else "paper"
                logger.info(f"MARKET_STREAM_STARTED: Bybit price feed ({mode_label}) for symbols {symbols}")

                # Auto-detect balance from exchange in live mode
                # System works with any amount - no need to specify INITIAL_CAPITAL
                try:
                    from hean.exchange.bybit.http import BybitHTTPClient
                    http_client = BybitHTTPClient()
                    await http_client.connect()
                    account_info = await http_client.get_account_info()
                    await http_client.disconnect()

                    # Parse balance from Bybit API response
                    # _request() returns result.get("result", {}) ‚Äî already unwrapped
                    balance = 0.0
                    account_list = account_info.get("list", [])
                    if account_list:
                        coins = account_list[0].get("coin", [])
                        for coin in coins:
                            if coin.get("coin") == "USDT":
                                balance = float(coin.get("walletBalance", 0))
                                break

                    if balance > 0:
                        # Update accounting with real exchange balance
                        self._accounting.set_balance_from_exchange(balance)
                        # Update deposit protector with real balance
                        self._deposit_protector.update_initial_capital(balance)
                        # Update killswitch with real balance
                        self._killswitch.set_initial_capital(balance)
                        # Update profit capture so it doesn't see config vs exchange diff as gain
                        if self._profit_capture:
                            self._profit_capture.sync_start_equity(balance)
                        logger.info(f"‚úÖ Synced with exchange balance: ${balance:,.2f} USDT")
                        logger.info("üìä System ready to trade with any capital amount")
                    else:
                        logger.warning(f"‚ö†Ô∏è Could not get balance from exchange, using config: ${initial_capital:,.2f}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Could not sync with exchange balance: {e}")
                    logger.info(f"Using configured initial capital: ${initial_capital:,.2f}")
            except Exception as e:
                logger.critical(f"FATAL: Bybit price feed failed. Cannot start without real market data. Error: {e}", exc_info=True)
                self._stop_trading = True
                await self._bus.publish(
                    Event(
                        event_type=EventType.KILLSWITCH_TRIGGERED,
                        data={
                            "reason": "bybit_price_feed_failure",
                            "error": str(e),
                        },
                    )
                )
                raise RuntimeError(
                    f"Cannot start trading system: Bybit price feed failed. "
                    f"No synthetic/simulated data fallback allowed. Error: {e}"
                ) from e
        else:
            # No live feed configured ‚Äî require Bybit connection
            raise RuntimeError(
                "Cannot start trading system without Bybit price feed. "
                "Set BYBIT_API_KEY/BYBIT_API_SECRET and ensure BYBIT_TESTNET=true. "
                "No synthetic/simulated data allowed in production."
            )

        # Start triangular arbitrage scanner (paper + live)
        if self._mode == "run" and settings.triangular_arb_enabled:
            try:
                self._triangular_scanner = TriangularScanner(
                    self._bus,
                    fee_buffer=settings.triangular_fee_buffer,
                    min_profit_bps=settings.triangular_min_profit_bps,
                )
                await self._triangular_scanner.start()
                logger.info("Triangular Arbitrage Scanner started")
            except Exception as e:
                logger.warning(f"Failed to start Triangular Arbitrage Scanner: {e}")

        # Killswitch auto-reset is enabled by default; keep testnet-friendly settings
        if settings.bybit_testnet and self._killswitch:
            self._killswitch.enable_auto_reset(True)
            logger.info("Killswitch configured for testnet: auto-reset enabled (15min cooldown, 10% recovery, max 10/day)")

        # Physics-Aware Position Sizing
        self._physics_positioner = None
        if self._mode == "run" and settings.physics_aware_sizing:
            try:
                from hean.strategies.physics_aware_positioner import PhysicsAwarePositioner
                self._physics_positioner = PhysicsAwarePositioner(bus=self._bus)
                await self._physics_positioner.start()
                logger.info("Physics-Aware Position Sizing started")
            except Exception as e:
                logger.warning(f"Physics-Aware Positioner failed to start: {e}")

        # Dynamic Oracle Weighting
        self._dynamic_oracle_weights = None
        if self._mode == "run" and settings.oracle_dynamic_weighting:
            try:
                from hean.core.intelligence.dynamic_oracle_weights import DynamicOracleWeightManager
                self._dynamic_oracle_weights = DynamicOracleWeightManager(bus=self._bus)
                await self._dynamic_oracle_weights.start()
                logger.info("Dynamic Oracle Weight Manager started")
            except Exception as e:
                logger.warning(f"Dynamic Oracle Weights failed to start: {e}")

        # Strategy Capital Allocator
        self._strategy_allocator = None
        if self._mode == "run" and settings.strategy_capital_allocation:
            try:
                from hean.portfolio.strategy_capital_allocator import StrategyCapitalAllocator
                capital = self._accounting.get_equity()
                self._strategy_allocator = StrategyCapitalAllocator(
                    bus=self._bus,
                    total_capital=capital,
                    allocation_method=settings.capital_allocation_method,
                )
                await self._strategy_allocator.start()
                logger.info(f"Strategy Capital Allocator started (method={settings.capital_allocation_method}, capital=${capital:.2f})")
            except Exception as e:
                logger.warning(f"Strategy Capital Allocator failed to start: {e}")

        # RL Risk Manager (PPO-based dynamic risk adjustment)
        self._rl_risk_manager = None
        if self._mode == "run" and settings.rl_risk_enabled:
            try:
                from hean.risk.rl_risk_manager import RLRiskManager
                self._rl_risk_manager = RLRiskManager(
                    bus=self._bus,
                    model_path=settings.rl_risk_model_path if settings.rl_risk_model_path else None,
                    adjustment_interval=settings.rl_risk_adjust_interval,
                    enabled=True,
                )
                await self._rl_risk_manager.start()
                logger.info(f"RL Risk Manager started (interval={settings.rl_risk_adjust_interval}s, model={'loaded' if settings.rl_risk_model_path else 'rule-based fallback'})")
            except Exception as e:
                logger.warning(f"RL Risk Manager failed to start: {e}")

        # Physics Signal Filter
        self._physics_filter = None
        if self._mode == "run" and settings.physics_filter_enabled:
            try:
                from hean.strategies.physics_signal_filter import PhysicsSignalFilter
                self._physics_filter = PhysicsSignalFilter(
                    bus=self._bus,
                    strict_mode=settings.physics_filter_strict,
                )
                await self._physics_filter.start()
                logger.info(f"Physics Signal Filter started (strict={settings.physics_filter_strict})")
            except Exception as e:
                logger.warning(f"Physics Signal Filter failed to start: {e}")

        # Ollama Sentiment Client (local LLM, free, alongside Brain)
        self._ollama_client = None
        if self._mode == "run" and settings.ollama_enabled:
            try:
                from hean.sentiment.ollama_client import OllamaSentimentClient
                self._ollama_client = OllamaSentimentClient(
                    bus=self._bus,
                    url=settings.ollama_url,
                    model=settings.ollama_model,
                    analysis_interval=settings.ollama_sentiment_interval,
                )
                await self._ollama_client.start()
                logger.info(f"Ollama Sentiment Client started (model={settings.ollama_model}, url={settings.ollama_url})")
            except Exception as e:
                logger.warning(f"Ollama Sentiment Client failed to start (is Ollama running?): {e}")

        # Risk Governor (RiskGovernor state machine: NORMAL ‚Üí SOFT_BRAKE ‚Üí QUARANTINE ‚Üí HARD_STOP)
        self._risk_governor = None
        if self._mode == "run":
            try:
                from hean.risk.risk_governor import RiskGovernor
                self._risk_governor = RiskGovernor(
                    bus=self._bus,
                    accounting=self._accounting,
                    killswitch=self._killswitch,
                )
                await self._risk_governor.start()
                logger.info("Risk Governor started (state machine: NORMAL ‚Üí SOFT_BRAKE ‚Üí QUARANTINE ‚Üí HARD_STOP)")
            except Exception as e:
                logger.warning(f"Risk Governor failed to start: {e}")

        # === Risk-First: RiskSentinel (pre-computes RiskEnvelope for strategies) ===
        if self._mode == "run" and settings.risk_sentinel_enabled:
            try:
                from hean.risk.risk_sentinel import RiskSentinel
                self._risk_sentinel = RiskSentinel(
                    bus=self._bus,
                    accounting=self._accounting,
                    order_manager=self._order_manager,
                    risk_governor=self._risk_governor,
                    killswitch=self._killswitch,
                    deposit_protector=self._deposit_protector,
                    risk_limits=self._risk_limits,
                    multi_level_protection=MultiLevelProtection(
                        initial_capital=self._accounting.initial_capital
                    ),
                    strategy_allocator=self._strategy_allocator,
                    capital_preservation=CapitalPreservationMode(),
                    stop_trading_flag=self._stop_trading,
                )
                # Set active strategies after they've been registered
                strategy_ids = [s.strategy_id for s in self._strategies]
                self._risk_sentinel.set_active_strategies(strategy_ids)
                await self._risk_sentinel.start()
                logger.info(
                    "RiskSentinel started (strategies=%d, interval=%dms)",
                    len(strategy_ids),
                    settings.risk_sentinel_update_interval_ms,
                )
            except Exception as e:
                logger.warning(f"RiskSentinel failed to start: {e}")

        # === Risk-First: IntelligenceGate (enriches signals with Brain+Oracle+Physics) ===
        if self._mode == "run" and settings.intelligence_gate_enabled:
            try:
                from hean.core.intelligence.intelligence_gate import IntelligenceGate
                self._intelligence_gate = IntelligenceGate(
                    bus=self._bus,
                    context_aggregator=self._context_aggregator,
                )
                await self._intelligence_gate.start()
                logger.info(
                    "IntelligenceGate started (reject_on_contradiction=%s)",
                    settings.intelligence_gate_reject_on_contradiction,
                )
            except Exception as e:
                logger.warning(f"IntelligenceGate failed to start: {e}")

        # Symbiont X GA Bridge
        self._symbiont_x_bridge = None
        if self._mode == "run" and settings.symbiont_x_enabled:
            try:
                from hean.symbiont_x.bridge import SymbiontXBridge
                self._symbiont_x_bridge = SymbiontXBridge(
                    bus=self._bus,
                    enabled=True,  # must be True ‚Äî checked above via settings.symbiont_x_enabled
                    generations=settings.symbiont_x_generations,
                    population_size=settings.symbiont_x_population_size,
                    mutation_rate=settings.symbiont_x_mutation_rate,
                    reoptimize_interval=settings.symbiont_x_reoptimize_interval,
                )
                await self._symbiont_x_bridge.start(strategy_configs={})
                logger.info(
                    "Symbiont X GA Bridge started (pop=%d, gens=%d)",
                    settings.symbiont_x_population_size,
                    settings.symbiont_x_generations,
                )
            except Exception as e:
                logger.warning(f"Symbiont X Bridge failed to start: {e}")

        # SovereignSymbiont ‚Äî Phase 3 live wiring (full EvolutionEngine bridge)
        if self._mode == "run" and getattr(settings, "symbiont_enabled", False):
            try:
                from hean.symbiont_x.bridge import SovereignSymbiont
                self._sovereign_symbiont = SovereignSymbiont(bus=self._bus, settings=settings)
                await self._sovereign_symbiont.start()
                logger.info(
                    "SovereignSymbiont started (pop=%d, interval=%ds)",
                    getattr(settings, "symbiont_population_size", 50),
                    getattr(settings, "symbiont_evolution_interval", 300),
                )
            except ImportError as e:
                logger.warning("SovereignSymbiont not available (missing deps): %s", e)
            except Exception as e:
                logger.warning("SovereignSymbiont failed to start: %s", e)

        # Digital Organism: DoomsdaySandbox (Stage 2)
        if self._mode == "run" and settings.doomsday_sandbox_enabled:
            try:
                from hean.risk.doomsday_sandbox import DoomsdaySandbox
                self._doomsday_sandbox = DoomsdaySandbox(
                    bus=self._bus,
                    accounting=self._accounting,
                )
                await self._doomsday_sandbox.start()
                logger.info("DoomsdaySandbox started (interval=%ds)", settings.doomsday_interval_sec)
            except Exception as e:
                logger.warning(f"DoomsdaySandbox failed to start: {e}")

        # Digital Organism: MarketGenomeDetector (Stage 1)
        if self._mode == "run" and settings.market_genome_enabled:
            try:
                from hean.core.intelligence.market_genome import MarketGenomeDetector
                self._market_genome_detector = MarketGenomeDetector(
                    bus=self._bus,
                    interval=settings.market_genome_interval,
                )
                await self._market_genome_detector.start()
                logger.info(f"MarketGenomeDetector started (interval={settings.market_genome_interval}s)")
            except Exception as e:
                logger.warning(f"MarketGenomeDetector failed to start: {e}")

        # Digital Organism: MetaStrategyBrain (Stage 3)
        if self._mode == "run" and settings.meta_brain_enabled:
            try:
                from hean.portfolio.meta_strategy_brain import MetaStrategyBrain
                self._meta_strategy_brain = MetaStrategyBrain(
                    bus=self._bus,
                    accounting=self._accounting,
                )
                await self._meta_strategy_brain.start()
                logger.info(
                    "MetaStrategyBrain started (eval_interval=%ds)",
                    settings.meta_brain_evaluation_interval,
                )
                # Also start EvolutionBridge
                from hean.portfolio.evolution_bridge import EvolutionBridge
                self._evolution_bridge = EvolutionBridge(bus=self._bus)
                await self._evolution_bridge.start()
            except Exception as e:
                logger.warning(f"MetaStrategyBrain failed to start: {e}")

        # Start strategies
        if settings.funding_harvester_enabled:
            strategy = FundingHarvester(self._bus, symbols)
            await strategy.start()
            self._strategies.append(strategy)

        if settings.basis_arbitrage_enabled:
            strategy = BasisArbitrage(self._bus, symbols)
            await strategy.start()
            self._strategies.append(strategy)

        if settings.impulse_engine_enabled:
            # Phase 1 Profit Doubling: Pass Oracle Engine and OFI Monitor to impulse_engine
            oracle_ref = getattr(self, '_oracle_integration', None)
            oracle_engine_obj = oracle_ref._oracle if oracle_ref else None

            # Initialize OFI Monitor if not already created
            if not hasattr(self, '_ofi_monitor'):
                from hean.core.ofi import OrderFlowImbalance
                self._ofi_monitor = OrderFlowImbalance(
                    self._bus,
                    lookback_window=20,
                    use_ml_prediction=True
                )
                await self._ofi_monitor.start()
                logger.info("OFI Monitor initialized for impulse_engine")

            strategy = ImpulseEngine(
                self._bus, symbols,
                oracle_engine=oracle_engine_obj,
                ofi_monitor=self._ofi_monitor
            )
            await strategy.start()
            self._strategies.append(strategy)
            self._impulse_engine = strategy  # Store reference for metrics
        else:
            self._impulse_engine = None

        # Phase 5: Register dormant strategies (AFO-Director dormant strategies)
        # HF Scalping - high frequency scalping for range/normal regimes
        if settings.hf_scalping_enabled:
            strategy = HFScalpingStrategy(self._bus, symbols)
            await strategy.start()
            self._strategies.append(strategy)
            logger.info("HF Scalping Strategy registered and started")

        # Enhanced Grid - grid trading for range-bound markets
        if settings.enhanced_grid_enabled:
            strategy = EnhancedGridStrategy(self._bus, symbols)
            await strategy.start()
            self._strategies.append(strategy)
            logger.info("Enhanced Grid Strategy registered and started")

        # Momentum Trader - momentum following strategy
        if settings.momentum_trader_enabled:
            strategy = MomentumTrader(self._bus, symbols)
            await strategy.start()
            self._strategies.append(strategy)
            logger.info("Momentum Trader Strategy registered and started")

        # Inventory Neutral Market Making
        if settings.inventory_neutral_mm_enabled:
            strategy = InventoryNeutralMM(
                self._bus,
                ofi_monitor=getattr(self, '_ofi_monitor', None),
                symbols=symbols,
            )
            await strategy.start()
            self._strategies.append(strategy)
            logger.info("Inventory Neutral MM Strategy registered and started")

        # Correlation Arbitrage
        if settings.correlation_arb_enabled:
            strategy = CorrelationArbitrage(self._bus)
            await strategy.start()
            self._strategies.append(strategy)
            logger.info("Correlation Arbitrage Strategy registered and started")

        # Rebate Farmer
        if settings.rebate_farmer_enabled:
            strategy = RebateFarmer(self._bus, symbols=symbols)
            await strategy.start()
            self._strategies.append(strategy)
            logger.info("Rebate Farmer Strategy registered and started")

        # Liquidity Sweep Detector
        if settings.liquidity_sweep_enabled:
            strategy = LiquiditySweepDetector(
                self._bus,
                symbols=symbols,
                ofi_monitor=getattr(self, '_ofi_monitor', None),
            )
            await strategy.start()
            self._strategies.append(strategy)
            logger.info("Liquidity Sweep Detector registered and started")

        # Sentiment Strategy
        if settings.sentiment_strategy_enabled:
            strategy = SentimentStrategy(self._bus, symbols=symbols)
            await strategy.start()
            self._strategies.append(strategy)
            logger.info("Sentiment Strategy registered and started")

        # Start income streams (infrastructure-level, paper-safe by default)
        if settings.stream_funding_enabled:
            stream = FundingHarvesterStream(self._bus, symbols)
            await stream.start()
            self._income_streams.append(stream)

        if settings.stream_maker_rebate_enabled:
            stream = MakerRebateStream(self._bus, symbols)
            await stream.start()
            self._income_streams.append(stream)

        if settings.stream_basis_enabled:
            stream = BasisHedgeStream(self._bus, symbols)
            await stream.start()
            self._income_streams.append(stream)

        if settings.stream_volatility_enabled:
            stream = VolatilityHarvestStream(self._bus, symbols)
            await stream.start()
            self._income_streams.append(stream)

        # Subscribe to events (Risk-First: use enriched signals if IntelligenceGate is active)
        if self._intelligence_gate:
            # IntelligenceGate: SIGNAL ‚Üí enrich ‚Üí ENRICHED_SIGNAL ‚Üí slim handler
            self._bus.subscribe(EventType.ENRICHED_SIGNAL, self._handle_enriched_signal)
        else:
            # Fallback: subscribe directly to SIGNAL with slim handler
            self._bus.subscribe(EventType.SIGNAL, self._handle_enriched_signal)
        self._bus.subscribe(EventType.ORDER_FILLED, self._handle_order_filled)
        self._bus.subscribe(EventType.POSITION_CLOSED, self._handle_position_closed)
        self._bus.subscribe(EventType.STOP_TRADING, self._handle_stop_trading)
        self._bus.subscribe(EventType.KILLSWITCH_TRIGGERED, self._handle_killswitch)
        self._bus.subscribe(EventType.KILLSWITCH_RESET, self._handle_killswitch_reset)
        # Subscribe to ticks for TP/SL checks, TTL, and mark-to-market updates
        self._bus.subscribe(EventType.TICK, self._handle_tick_forced_exit)
        # Subscribe to POSITION_CLOSE_REQUEST from Oracle/other modules
        self._bus.subscribe(EventType.POSITION_CLOSE_REQUEST, self._handle_position_close_request)

        # External microservices bridge (Redis streams -> EventBus)
        if self._mode == "run" and (use_redis_physics or use_redis_brain or use_redis_risk):
            try:
                from hean.core.microservices_bridge import MicroservicesBridge

                bridge_symbols = settings.symbols if settings.multi_symbol_enabled else settings.trading_symbols
                self._microservices_bridge = MicroservicesBridge(
                    bus=self._bus,
                    redis_url=settings.redis_url,
                    symbols=bridge_symbols,
                    consume_physics=use_redis_physics,
                    consume_brain=use_redis_brain,
                    consume_risk=use_redis_risk,
                    group_prefix=settings.microservices_group_prefix,
                )
                await self._microservices_bridge.start()
                logger.info(
                    "Microservices bridge active: physics=%s brain=%s risk=%s",
                    use_redis_physics,
                    use_redis_brain,
                    use_redis_risk,
                )
            except Exception as e:
                logger.warning(f"Failed to start microservices bridge: {e}")

        # Schedule periodic status updates (skip in evaluate mode)
        if self._mode == "run":
            self._clock.schedule_periodic(self._print_status, timedelta(seconds=10))
            # Anti-stuck: periodic TTL/NO_TICKS checks even if feed stalls
            self._clock.schedule_periodic(self._check_position_timeouts, timedelta(seconds=5))

            # Start fallback micro-trade task if paper assist enabled
            if is_paper_assist_enabled():
                self._micro_trade_task = asyncio.create_task(self._micro_trade_fallback_loop())
                logger.info("Paper Trade Assist: Fallback micro-trade loop started")

        # Start improvement catalyst (only in run mode)
        if self._mode == "run":
            try:
                # Create strategy dict for catalyst
                strategy_dict = {strategy.strategy_id: strategy for strategy in self._strategies}
                self._improvement_catalyst = ImprovementCatalyst(
                    bus=self._bus,
                    accounting=self._accounting,
                    strategies=strategy_dict,
                    ai_factory=self._ai_factory,
                    check_interval_minutes=30,
                    min_trades_for_analysis=10,
                )
                await self._improvement_catalyst.start()
                logger.info("Improvement Catalyst started")
            except Exception as e:
                logger.warning(f"Could not start Improvement Catalyst: {e}")

        # Start AI Council (multi-model periodic system review)
        if self._mode == "run" and settings.council_enabled:
            try:
                from hean.council.council import AICouncil

                strategy_dict = {s.strategy_id: s for s in self._strategies}
                self._council = AICouncil(
                    bus=self._bus,
                    accounting=self._accounting,
                    strategies=strategy_dict,
                    killswitch=self._killswitch,
                    ai_factory=self._ai_factory,
                    improvement_catalyst=self._improvement_catalyst,
                    review_interval=settings.council_review_interval,
                    auto_apply_safe=settings.council_auto_apply_safe,
                )
                await self._council.start()
                logger.info("AI Council started")
            except Exception as e:
                logger.warning(f"Could not start AI Council: {e}")

        # Start Trade Council 2.0 (real-time adversarial signal evaluation)
        if self._mode == "run" and settings.trade_council_enabled:
            try:
                from hean.council.trade_council import TradeCouncil

                self._trade_council = TradeCouncil(
                    bus=self._bus,
                    entry_threshold=settings.trade_council_entry_threshold,
                    exit_threshold=settings.trade_council_exit_threshold,
                    enabled=True,
                )
                await self._trade_council.start()
                logger.info("Trade Council 2.0 started")
            except Exception as e:
                logger.warning(f"Could not start Trade Council: {e}")

        # AutoPilot Coordinator ‚Äî meta-brain for autonomous self-improvement
        if self._mode == "run" and getattr(settings, 'autopilot_enabled', False):
            try:
                from hean.core.autopilot.coordinator import AutoPilotCoordinator

                self._autopilot = AutoPilotCoordinator(
                    bus=self._bus,
                    learning_period_sec=float(
                        getattr(settings, 'autopilot_learning_period_sec', 3600)
                    ),
                    eval_interval_sec=float(
                        getattr(settings, 'autopilot_eval_interval_sec', 30)
                    ),
                    journal_db_path=getattr(
                        settings, 'autopilot_journal_db_path',
                        'data/autopilot_journal.duckdb',
                    ),
                )
                await self._autopilot.start()
                logger.info("AutoPilot Coordinator started")
            except Exception as e:
                logger.warning(f"Could not start AutoPilot Coordinator: {e}")

        # Temporal Event Fabric ‚Äî causal genome tracking + EEV priority
        if settings.fabric_enabled:
            self._fabric_registry = CausalRegistry(maxsize=20_000)
            self._fabric_eev = EEVScorer()
            logger.info("Temporal Event Fabric enabled (DNA tracking + EEV scoring)")

        # ARCHON ‚Äî Central Brain-Orchestrator
        if settings.archon_enabled:
            try:
                from hean.archon.archon import Archon

                self._archon = Archon(bus=self._bus, settings=settings)
                await self._archon.start(
                    accounting=self._accounting,
                    order_manager=self._order_manager,
                    bybit_http=getattr(self._execution_router, "_bybit_http", None),
                )
                logger.info("ARCHON Brain-Orchestrator started")
            except Exception as e:
                logger.error(f"[ARCHON] Failed to start: {e}", exc_info=True)
                self._archon = None

        # Risk-First: publish the initial RiskEnvelope NOW that all strategies
        # have called start() and subscribed to RISK_ENVELOPE events.
        #
        # RACE CONDITION FIXED: RiskSentinel.start() (called ~line 856) deliberately
        # defers the initial publish.  If it published immediately, strategies that
        # hadn't started yet would miss it and begin running with _risk_envelope=None,
        # causing every early signal to be treated as "no risk limits known" and
        # either silently rejected or passed through without proper sizing.
        if self._risk_sentinel is not None:
            try:
                await self._risk_sentinel.publish_initial_envelope()
            except Exception as e:
                logger.warning(f"RiskSentinel initial envelope publish failed: {e}")

        self._running = True
        logger.info("Trading system started")

    async def stop(self) -> None:
        """Stop the trading system."""
        logger.info("Stopping trading system...")
        self._running = False

        # Stop ARCHON first
        if self._archon:
            try:
                await self._archon.stop()
            except Exception as e:
                logger.error(f"[ARCHON] Error during stop: {e}", exc_info=True)

        # Stop AI Council
        if self._council:
            await self._council.stop()

        # Stop Trade Council
        if self._trade_council:
            await self._trade_council.stop()

        # Stop AutoPilot Coordinator
        if self._autopilot:
            await self._autopilot.stop()

        # Stop improvement catalyst
        if self._improvement_catalyst:
            await self._improvement_catalyst.stop()

        # Stop strategies
        for strategy in self._strategies:
            await strategy.stop()

        # Stop income streams
        for stream in self._income_streams:
            await stream.stop()

        # Stop price feed
        if self._price_feed:
            await self._price_feed.stop()
        if hasattr(self, "_bybit_ws_public") and self._bybit_ws_public:
            await self._bybit_ws_public.disconnect()

        # Stop triangular arbitrage scanner
        if self._triangular_scanner:
            await self._triangular_scanner.stop()

        # Stop candle aggregation
        if self._candle_aggregator:
            await self._candle_aggregator.stop()

        # Stop Position Monitor
        await self._position_monitor.stop()

        # Stop Position Reconciler
        if self._position_reconciler:
            await self._position_reconciler.stop()

        # Stop ContextAggregator
        if self._context_aggregator:
            await self._context_aggregator.stop()

        # Stop self-insight collector
        if self._self_insight_collector:
            await self._self_insight_collector.stop()

        # Stop external microservices bridge
        if self._microservices_bridge:
            await self._microservices_bridge.stop()

        # Stop Brain Client
        if hasattr(self, '_brain_client') and self._brain_client:
            await self._brain_client.stop()

        # Stop DuckDB Storage
        if hasattr(self, '_duckdb_store') and self._duckdb_store:
            await self._duckdb_store.stop()

        # Stop Physics Engine components
        if self._physics_engine:
            await self._physics_engine.stop()
        if self._participant_classifier:
            await self._participant_classifier.stop()

        # Phase 5: Stop Statistical Arbitrage & Anti-Fragile Architecture
        if self._self_healing:
            await self._self_healing.stop()
        if self._safety_net:
            await self._safety_net.stop()
        if self._correlation_engine:
            await self._correlation_engine.stop()

        # Stop Risk-First components
        if self._intelligence_gate:
            await self._intelligence_gate.stop()
        if self._risk_sentinel:
            await self._risk_sentinel.stop()

        # Unsubscribe all TradingSystem event handlers (fixes leak of 8 handlers)
        self._bus.unsubscribe(EventType.REGIME_UPDATE, self._handle_regime_update)
        # Risk-First: unsubscribe from whichever signal event we subscribed to
        if self._intelligence_gate:
            self._bus.unsubscribe(EventType.ENRICHED_SIGNAL, self._handle_enriched_signal)
        else:
            self._bus.unsubscribe(EventType.SIGNAL, self._handle_enriched_signal)
        self._bus.unsubscribe(EventType.ORDER_FILLED, self._handle_order_filled)
        self._bus.unsubscribe(EventType.POSITION_CLOSED, self._handle_position_closed)
        self._bus.unsubscribe(EventType.STOP_TRADING, self._handle_stop_trading)
        self._bus.unsubscribe(EventType.KILLSWITCH_TRIGGERED, self._handle_killswitch)
        self._bus.unsubscribe(EventType.KILLSWITCH_RESET, self._handle_killswitch_reset)
        self._bus.unsubscribe(EventType.TICK, self._handle_tick_forced_exit)
        self._bus.unsubscribe(EventType.POSITION_CLOSE_REQUEST, self._handle_position_close_request)

        # Stop regime detector
        await self._regime_detector.stop()

        # Stop micro-trade task
        if self._micro_trade_task:
            self._micro_trade_task.cancel()
            try:
                await self._micro_trade_task
            except asyncio.CancelledError:
                pass

        # Stop new wired modules
        if self._physics_positioner:
            await self._physics_positioner.stop()
        if self._dynamic_oracle_weights:
            await self._dynamic_oracle_weights.stop()
        if self._strategy_allocator:
            await self._strategy_allocator.stop()
        if hasattr(self, '_rl_risk_manager') and self._rl_risk_manager:
            await self._rl_risk_manager.stop()
        if hasattr(self, '_physics_filter') and self._physics_filter:
            await self._physics_filter.stop()
        if hasattr(self, '_ollama_client') and self._ollama_client:
            await self._ollama_client.stop()
        if hasattr(self, '_risk_governor') and self._risk_governor:
            await self._risk_governor.stop()
        if hasattr(self, '_symbiont_x_bridge') and self._symbiont_x_bridge:
            await self._symbiont_x_bridge.stop()
        if hasattr(self, '_sovereign_symbiont') and self._sovereign_symbiont:
            await self._sovereign_symbiont.stop()

        # Stop Digital Organism components
        if self._market_genome_detector:
            await self._market_genome_detector.stop()
        if self._doomsday_sandbox:
            await self._doomsday_sandbox.stop()
        if self._meta_strategy_brain:
            await self._meta_strategy_brain.stop()
        if self._evolution_bridge:
            await self._evolution_bridge.stop()

        # Stop core components
        await self._execution_router.stop()
        if self._health_check:
            await self._health_check.stop()
        await self._clock.stop()
        await self._bus.stop()

        logger.info("Trading system stopped")

    async def _handle_enriched_signal(self, event: Event) -> None:
        """Risk-First signal handler ‚Äî slim replacement for _handle_signal_legacy.

        Handles both ENRICHED_SIGNAL (from IntelligenceGate) and raw SIGNAL
        (when IntelligenceGate is disabled). Pre-computable risk checks are
        already performed by RiskSentinel (envelope) + BaseStrategy (tick filter).

        Only performs signal-specific checks that CANNOT be pre-computed:
        1. stop_loss validation (mandatory, signal-specific)
        2. Envelope freshness verification (final gate)
        3. DecisionMemory block/penalty (context-dependent)
        4. Position sizing with envelope multipliers + intelligence boost
        5. Live risk_limits validation (final safety check)
        6. ORDER_REQUEST creation and publish
        """
        signal: Signal = event.data["signal"]
        logger.debug(f"[ENRICHED] Signal received: {signal.strategy_id} {signal.symbol} {signal.side}")

        # Fabric: spawn SIGNAL DNA from cached TICK parent
        signal_dna: EventDNA | None = None
        if self._fabric_registry is not None:
            parent = self._fabric_tick_dna.get(signal.symbol)
            if parent:
                signal_dna = self._fabric_registry.spawn(parent.event_id, event)
            else:
                signal_dna = self._fabric_registry.register(event)
            inject_dna(event, signal_dna)

        # === 1. Mandatory stop_loss validation ===
        if signal.stop_loss is None:
            logger.warning(
                f"Signal REJECTED: missing stop_loss (strategy={signal.strategy_id}, "
                f"symbol={signal.symbol}, side={signal.side})"
            )
            no_trade_report.increment("missing_stop_loss", signal.symbol, signal.strategy_id)
            await self._emit_order_decision(
                signal=signal,
                decision="REJECT",
                reason_code="MISSING_STOP_LOSS",
                computed_qty=None,
                context={"error": "Signals without stop_loss represent unbounded risk"},
            )
            return

        # === 2. Envelope freshness check (final gate) ===
        envelope: RiskEnvelope | None = None
        if self._risk_sentinel:
            envelope = self._risk_sentinel.get_envelope()
            if envelope:
                if not envelope.trading_allowed:
                    await self._emit_order_decision(
                        signal=signal,
                        decision="SKIP",
                        reason_code="TRADING_DISABLED",
                        computed_qty=None,
                        context={"risk_state": envelope.risk_state, "note": "envelope.trading_allowed=False"},
                    )
                    return
                if not envelope.can_open_new_position:
                    await self._emit_order_decision(
                        signal=signal,
                        decision="SKIP",
                        reason_code="LIMIT_REACHED",
                        computed_qty=None,
                        context={
                            "open_positions": envelope.open_positions,
                            "open_orders": envelope.open_orders,
                        },
                    )
                    return
                if signal.symbol in envelope.blocked_symbols:
                    await self._emit_order_decision(
                        signal=signal,
                        decision="SKIP",
                        reason_code="SYMBOL_BLOCKED",
                        computed_qty=None,
                        context={"blocked_symbols": list(envelope.blocked_symbols)},
                    )
                    return
                if envelope.strategy_cooldowns.get(signal.strategy_id, False):
                    await self._emit_order_decision(
                        signal=signal,
                        decision="SKIP",
                        reason_code="COOLDOWN",
                        computed_qty=None,
                        context={"strategy_id": signal.strategy_id},
                    )
                    return
        else:
            # Legacy fallback: manual checks when RiskSentinel is not running
            if self._stop_trading:
                await self._emit_order_decision(
                    signal=signal, decision="SKIP", reason_code="TRADING_DISABLED",
                    computed_qty=None, context={"note": "stop_trading flag set"},
                )
                return
            open_positions = len(self._accounting.get_positions())
            open_orders = len(self._order_manager.get_open_orders())
            if open_positions >= settings.max_open_positions or open_orders >= settings.max_open_orders:
                await self._emit_order_decision(
                    signal=signal, decision="SKIP", reason_code="LIMIT_REACHED",
                    computed_qty=None,
                    context={"open_positions": open_positions, "open_orders": open_orders},
                )
                return

        # Track signal attempt
        self._signals_generated += 1
        metrics.increment("signals_generated_total")

        # === 2.5 Trade Council evaluation (adversarial pre-trade vote) ===
        if self._trade_council:
            # Feed fresh strategy metrics to council
            try:
                s_metrics = self._accounting.get_strategy_metrics() or {}
                self._trade_council.update_strategy_metrics(s_metrics)
            except Exception:
                pass
            signal_data = {
                "signal_id": f"{signal.strategy_id}_{signal.symbol}_{event.timestamp.isoformat()}",
                "strategy_id": signal.strategy_id,
                "symbol": signal.symbol,
                "side": signal.side,
                "entry_price": signal.entry_price,
                "stop_loss": signal.stop_loss,
                "take_profit": signal.take_profit,
                "confidence": signal.confidence,
                "urgency": signal.urgency,
                "spread_bps": (signal.metadata or {}).get("spread_bps"),
                "funding_rate": (signal.metadata or {}).get("funding_rate"),
                "metadata": signal.metadata or {},
            }
            verdict = self._trade_council.evaluate(signal_data)
            if not verdict.approved:
                reason = "COUNCIL_VETOED" if verdict.vetoed else "COUNCIL_REJECTED"
                no_trade_report.increment("trade_council_block", signal.symbol, signal.strategy_id)
                await self._emit_order_decision(
                    signal=signal,
                    decision="REJECT",
                    reason_code=reason,
                    computed_qty=None,
                    context={
                        "council_confidence": verdict.final_confidence,
                        "vetoed_by": verdict.vetoed_by,
                        "votes": [
                            {"agent": v.agent_role, "confidence": v.confidence, "reasoning": v.reasoning}
                            for v in verdict.votes
                        ],
                    },
                )
                return
            # Attach verdict to signal metadata for downstream use
            if signal.metadata is None:
                signal.metadata = {}
            signal.metadata["council_confidence"] = verdict.final_confidence
            signal.metadata["council_signal_id"] = verdict.signal_id

        # === 3. Get current price ===
        current_price = signal.entry_price or self._regime_detector.get_price(signal.symbol)
        if not current_price or current_price <= 0:
            await self._emit_order_decision(
                signal=signal, decision="SKIP", reason_code="VALIDATION_FAIL",
                computed_qty=None, context={"reason": "missing_price"},
            )
            return

        # === 4. DecisionMemory (context-dependent, cannot be pre-computed) ===
        regime = self._current_regime.get(signal.symbol, Regime.NORMAL)
        spread_bps = (signal.metadata or {}).get("spread_bps")
        volatility = self._regime_detector.get_volatility(signal.symbol)
        dm_context = self._decision_memory.build_context(
            regime=regime, spread_bps=spread_bps,
            volatility=volatility, timestamp=event.timestamp,
        )
        has_dm_history = self._decision_memory.has_history(signal.strategy_id, dm_context)
        if has_dm_history and self._decision_memory.blocked(signal.strategy_id, dm_context):
            no_trade_report.increment("decision_memory_block", signal.symbol, signal.strategy_id)
            no_trade_report.increment_pipeline("signals_blocked_decision_memory", signal.strategy_id)
            await self._emit_order_decision(
                signal=signal, decision="SKIP", reason_code="DECISION_MEMORY",
                computed_qty=None, context={"context": dm_context},
            )
            return

        # === 5. Position sizing ===
        equity = self._accounting.get_equity()
        sizing_equity = equity
        risk_size_multiplier = 1.0

        if envelope:
            sizing_equity = envelope.strategy_budgets.get(signal.strategy_id, equity)
            risk_size_multiplier = envelope.risk_size_multiplier
        elif self._strategy_allocator:
            allocated = self._strategy_allocator.get_allocation(signal.strategy_id)
            if allocated is not None and allocated > 0:
                sizing_equity = allocated

        # Gather sizing parameters
        rolling_pf = 1.0
        strategy_metrics = self._accounting.get_strategy_metrics()
        if strategy_metrics:
            signal_metrics = strategy_metrics.get(signal.strategy_id)
            if signal_metrics:
                rolling_pf = signal_metrics.get("profit_factor", 1.0)

        _, drawdown_pct = self._accounting.get_drawdown(equity)
        volatility_percentile = None
        current_volatility = self._regime_detector.get_volatility(signal.symbol)
        if current_volatility > 0:
            self._position_sizer.update_volatility(current_volatility)
            dynamic_risk = self._position_sizer.get_dynamic_risk_manager()
            volatility_percentile = dynamic_risk.calculate_volatility_percentile(current_volatility)

        edge_bps = (signal.metadata or {}).get("edge_bps")

        # Calculate base size
        base_size = signal.size or self._position_sizer.calculate_size(
            signal, sizing_equity, current_price, regime,
            rolling_pf=rolling_pf, recent_drawdown=drawdown_pct,
            volatility_percentile=volatility_percentile, edge_bps=edge_bps,
        )

        if base_size <= 0:
            base_size = max((equity * 0.001) / current_price, 0.001)

        # Physics-Aware adjustment
        if self._physics_positioner:
            adjusted = self._physics_positioner.get_physics_adjusted_signal(signal)
            if adjusted is None:
                await self._emit_order_decision(
                    signal=signal, decision="REJECT", reason_code="PHYSICS_BLOCK",
                    computed_qty=base_size,
                    context={"note": "Physics-Aware Positioner blocked signal"},
                )
                return
            physics_mult = (adjusted.metadata or {}).get("physics_size_mult", 1.0)
            if physics_mult != 1.0:
                base_size *= physics_mult

        # Apply envelope risk multiplier (RiskGovernor + Capital Preservation)
        base_size *= risk_size_multiplier

        # Intelligence boost from IntelligenceGate enrichment
        intelligence_boost = (signal.metadata or {}).get("intelligence_boost", 1.0)
        base_size *= intelligence_boost

        # Decision memory penalty + signal metadata multiplier
        penalty = self._decision_memory.penalty(signal.strategy_id, dm_context)
        signal_mult = 1.0
        if signal.metadata and "size_multiplier" in signal.metadata:
            try:
                signal_mult = min(float(signal.metadata["size_multiplier"]), 1.0)
            except (TypeError, ValueError):
                signal_mult = 1.0

        size = base_size * min(penalty * signal_mult, 1.0)

        # Enforce minimum viable size
        min_size = max((equity * 0.001) / current_price, 0.001)
        if size < min_size:
            size = min_size

        # === 6. Final live risk_limits validation ===
        external_risk_approved = bool((signal.metadata or {}).get("external_risk_approved"))
        if not external_risk_approved:
            allowed, reason = self._risk_limits.check_order_request(
                OrderRequest(
                    signal_id=str(uuid.uuid4()),
                    strategy_id=signal.strategy_id,
                    symbol=signal.symbol,
                    side=signal.side,
                    size=size,
                    price=signal.entry_price,
                ),
                equity,
            )
            if not allowed:
                metrics.increment("signals_rejected")
                no_trade_report.increment("risk_limits_reject", signal.symbol, signal.strategy_id)
                await self._emit_order_decision(
                    signal=signal, decision="REJECT", reason_code="RISK_BLOCKED",
                    computed_qty=size, context={"reason": reason, "equity": equity},
                )
                return

            allowed, reason = self._risk_limits.check_daily_attempts(signal.strategy_id, regime)
            if not allowed:
                metrics.increment("signals_rejected")
                no_trade_report.increment("daily_attempts_reject", signal.symbol, signal.strategy_id)
                await self._emit_order_decision(
                    signal=signal, decision="SKIP", reason_code="DAILY_LIMIT",
                    computed_qty=size, context={"reason": reason},
                )
                return

        # === 7. Build order metadata and create ORDER_REQUEST ===
        if signal.metadata is None:
            signal.metadata = {}

        sizing_details = self._position_sizer.get_last_calculation() or {}
        applied_leverage = max(1.0, float(sizing_details.get("leverage", 1.0)))
        exit_plan = {
            "tp": signal.take_profit,
            "sl": signal.stop_loss,
            "trailing": signal.metadata.get("trailing"),
            "time_stop_seconds": signal.metadata.get("time_stop_seconds")
            or signal.metadata.get("max_time_sec"),
            "invalidation_rule": signal.metadata.get("invalidation_rule"),
        }
        expected_pnl = self._calculate_expected_pnl(
            side=signal.side, entry_price=signal.entry_price,
            qty=size, take_profit=signal.take_profit, stop_loss=signal.stop_loss,
        )
        rationale = {
            "strategy_name": signal.strategy_id,
            "entry_reason": signal.metadata.get("entry_reason")
            or signal.metadata.get("reason") or "Strategy signal",
            "confidence": signal.metadata.get("confidence")
            or signal.metadata.get("edge_bps") or sizing_details.get("edge_bps"),
        }

        order_metadata = {
            **(signal.metadata or {}),
            "exit_plan": exit_plan,
            "expected_pnl": expected_pnl,
            "rationale": rationale,
            "applied_leverage": applied_leverage,
        }

        # Use council signal_id for post-trade reputation tracking if available
        signal_id = (signal.metadata or {}).get("council_signal_id") or str(uuid.uuid4())
        order_request = OrderRequest(
            signal_id=signal_id,
            strategy_id=signal.strategy_id,
            symbol=signal.symbol,
            side=signal.side,
            size=size,
            price=signal.entry_price,
            order_type="market",
            stop_loss=signal.stop_loss,
            take_profit=signal.take_profit,
            metadata=order_metadata,
        )
        order_request.metadata["signal_id"] = signal_id

        # Track and record
        no_trade_report.increment_pipeline("orders_created", signal.strategy_id)
        self._risk_limits.record_attempt(signal.strategy_id)
        self._signals_after_filters += 1
        self._orders_sent += 1
        metrics.increment("signals_after_filters_total")
        metrics.increment("orders_sent_total")

        # Emit ORDER_DECISION telemetry
        await self._emit_order_decision(
            signal=signal,
            decision="CREATE",
            reason_code="ACCEPTED",
            computed_qty=size,
            context={
                "price": current_price,
                "notional": size * current_price,
                "applied_leverage": applied_leverage,
                "equity": equity,
                "sizing_equity": sizing_equity,
                "risk_size_multiplier": risk_size_multiplier,
                "intelligence_boost": intelligence_boost,
                "exit_plan": exit_plan,
                "expected_pnl": expected_pnl,
            },
        )

        # === 8. Publish ORDER_REQUEST ===
        logger.info(
            f"[ORDER] {signal.strategy_id} {signal.symbol} {signal.side} "
            f"size={size:.6f} @ {current_price:.2f} "
            f"(risk_mult={risk_size_multiplier:.2f}, intel_boost={intelligence_boost:.2f})"
        )
        order_event = Event(
            event_type=EventType.ORDER_REQUEST,
            data={"order_request": order_request},
        )
        # Fabric: spawn ORDER_REQUEST DNA from SIGNAL parent
        if self._fabric_registry is not None and signal_dna is not None:
            or_dna = self._fabric_registry.spawn(signal_dna.event_id, order_event)
            inject_dna(order_event, or_dna)
        await self._bus.publish(order_event)
        metrics.increment("signals_accepted")
        log_allow_reason(
            "ALLOW", symbol=signal.symbol, strategy_id=signal.strategy_id,
            note=f"OrderRequest created: size={size:.6f}",
        )

    async def _handle_signal_legacy(self, event: Event) -> None:
        """[LEGACY] Original 700-line signal handler ‚Äî kept for one release cycle."""
        if self._stop_trading:
            logger.debug("Trading stopped, ignoring signal")
            signal: Signal = event.data["signal"]
            await self._emit_order_decision(
                signal=signal,
                decision="SKIP",
                reason_code="TRADING_DISABLED",
                computed_qty=None,
                context={
                    "note": "stop_trading flag set",
                    "open_orders": len(self._order_manager.get_open_orders()),
                    "open_positions": len(self._accounting.get_positions()),
                },
            )
            return

        signal: Signal = event.data["signal"]
        logger.debug(f"Signal received: {signal.strategy_id} {signal.symbol} {signal.side}")
        external_risk_approved = bool((signal.metadata or {}).get("external_risk_approved"))

        # CRITICAL: Mandatory stop_loss validation
        # Signals without stop_loss cannot be properly sized and represent unbounded risk
        if signal.stop_loss is None:
            logger.warning(
                f"Signal REJECTED: missing stop_loss (strategy={signal.strategy_id}, "
                f"symbol={signal.symbol}, side={signal.side})"
            )
            no_trade_report.increment("missing_stop_loss", signal.symbol, signal.strategy_id)
            await self._emit_order_decision(
                signal=signal,
                decision="REJECT",
                reason_code="MISSING_STOP_LOSS",
                computed_qty=None,
                context={
                    "error": "Signals without stop_loss represent unbounded risk",
                    "fix": "Add stop_loss to signal before publishing",
                },
            )
            return

        # Track signal attempt for diagnostics

        # Hard guards against runaway state (anti-stuck)
        open_positions = len(self._accounting.get_positions())
        open_orders = len(self._order_manager.get_open_orders())
        if open_positions >= settings.max_open_positions or open_orders >= settings.max_open_orders:
            await self._emit_order_decision(
                signal=signal,
                decision="SKIP",
                reason_code="LIMIT_REACHED",
                computed_qty=None,
                context={
                    "note": "risk guard: max positions/orders reached",
                    "open_positions": open_positions,
                    "open_orders": open_orders,
                    "max_open_positions": settings.max_open_positions,
                    "max_open_orders": settings.max_open_orders,
                },
            )
            log_block_reason(
                reason_code="max_positions_orders",
                symbol=signal.symbol,
                strategy_id=signal.strategy_id,
                reasons=["max_open_positions/orders reached"],
                suggested_fix=[
                    f"Close positions below {settings.max_open_positions}",
                    f"Reduce open orders below {settings.max_open_orders}",
                ],
            )
            return

        # Total exposure guard: block if total notional > max_exposure_multiplier * equity
        equity = self._accounting.get_equity()
        if equity > 0:
            total_notional = 0.0
            for pos in self._accounting.get_positions():
                pos_price = pos.current_price or pos.entry_price
                if pos_price:
                    total_notional += abs(pos.size) * pos_price
            max_notional = equity * settings.max_exposure_multiplier
            if total_notional >= max_notional:
                logger.warning(
                    f"Signal BLOCKED by exposure guard: total_notional=${total_notional:.2f} >= "
                    f"max=${max_notional:.2f} ({settings.max_exposure_multiplier}x equity=${equity:.2f})"
                )
                no_trade_report.increment("exposure_guard_block", signal.symbol, signal.strategy_id)
                await self._emit_order_decision(
                    signal=signal,
                    decision="REJECT",
                    reason_code="EXPOSURE_LIMIT",
                    computed_qty=None,
                    context={
                        "total_notional": total_notional,
                        "max_notional": max_notional,
                        "equity": equity,
                        "exposure_ratio": total_notional / equity,
                    },
                )
                return

        # WHY NOT TRADING: Check basic execution gates first
        if settings.process_factory_enabled:
            from hean.process_factory.integrations.trade_diagnostics import (
                check_dry_run,
                check_live_enabled,
                check_process_factory_actions,
                log_trade_blocked,
            )

            blocked_reasons = []
            suggested_fixes = []

            # Check live enabled
            live_ok, live_reasons, live_fixes = check_live_enabled()
            if not live_ok:
                blocked_reasons.extend(live_reasons)
                suggested_fixes.extend(live_fixes)

            # Check dry run
            dry_run_ok, dry_reasons, dry_fixes = check_dry_run()
            if not dry_run_ok:
                blocked_reasons.extend(dry_reasons)
                suggested_fixes.extend(dry_fixes)

            # Check process factory actions
            actions_ok, actions_reasons, actions_fixes = check_process_factory_actions()
            if not actions_ok:
                blocked_reasons.extend(actions_reasons)
                suggested_fixes.extend(actions_fixes)

            if blocked_reasons:
                log_trade_blocked(
                    symbol=signal.symbol,
                    strategy_id=signal.strategy_id,
                    reasons=blocked_reasons,
                    suggested_fix=suggested_fixes,
                )
                # Don't return here - continue with other checks for diagnostics

        # CRITICAL: Check deposit protection FIRST (before all other checks)
        if settings.deposit_protection_active:
            equity = self._accounting.get_equity()
            is_safe, reason = self._deposit_protector.check_equity(equity)
            if not is_safe:
                logger.warning(f"Signal blocked by deposit protector: {reason}")
                metrics.increment("signals_blocked_deposit_protection")
                no_trade_report.increment(
                    "deposit_protection_block", signal.symbol, signal.strategy_id
                )
                await self._emit_order_decision(
                    signal=signal,
                    decision="REJECT",
                    reason_code="DEPOSIT_PROTECTION",
                    computed_qty=None,
                    context={
                        "reason": reason,
                        "equity": equity,
                        "available_cash": self._accounting.get_cash_balance(),
                        "open_orders": len(self._order_manager.get_open_orders()),
                        "open_positions": len(self._accounting.get_positions()),
                    },
                )
                if settings.process_factory_enabled:
                    log_trade_blocked(
                        symbol=signal.symbol,
                        strategy_id=signal.strategy_id,
                        reasons=[f"deposit_protection: {reason}"],
                        suggested_fix=["Check account equity vs initial capital"],
                    )
                return

        # DEBUG: Track signal generation
        self._signals_generated += 1
        metrics.increment("signals_generated_total")

        # –ú–ù–û–ñ–ï–°–¢–í–ï–ù–ù–ê–Ø –ó–ê–©–ò–¢–ê (always active ‚Äî never bypass risk controls)
        protection_size_multiplier = 1.0
        equity = self._accounting.get_equity()
        initial_capital = self._accounting.initial_capital
        protection = MultiLevelProtection(initial_capital=initial_capital)

        allowed, reason = protection.check_all_protections(
            strategy_id=signal.strategy_id, equity=equity, initial_capital=initial_capital
        )

        if not allowed:
            logger.warning(f"Signal blocked by protection: {reason}")
            metrics.increment("signals_blocked_protection")
            no_trade_report.increment("protection_block", signal.symbol, signal.strategy_id)
            no_trade_report.increment_pipeline("signals_blocked_protection", signal.strategy_id)
            await self._emit_order_decision(
                signal=signal,
                decision="REJECT",
                reason_code="PROTECTION_BLOCK",
                computed_qty=None,
                context={
                    "reason": reason,
                    "equity": equity,
                    "initial_capital": initial_capital,
                    "open_orders": len(self._order_manager.get_open_orders()),
                    "open_positions": len(self._accounting.get_positions()),
                },
            )
            return

        # Get equity for later use
        equity = self._accounting.get_equity()

        # Capital Preservation Mode (always active)
        preservation_mode = CapitalPreservationMode()
        drawdown_pct = self._accounting.get_drawdown(equity)[1]
        strategy_metrics = self._accounting.get_strategy_metrics()
        rolling_pf = (
            strategy_metrics.get(signal.strategy_id, {}).get("profit_factor", 1.0)
            if strategy_metrics
            else 1.0
        )
        consecutive_losses = self._risk_limits.get_consecutive_losses(signal.strategy_id)

        if preservation_mode.should_activate(drawdown_pct, rolling_pf, consecutive_losses):
            if signal.metadata is None:
                signal.metadata = {}
            signal.metadata["preservation_mode"] = True
            signal.metadata["risk_multiplier"] = preservation_mode.get_risk_pct(1.0)
            logger.warning(
                f"Capital Preservation Mode active: drawdown={drawdown_pct:.1f}%, "
                f"PF={rolling_pf:.2f}, consecutive_losses={consecutive_losses}"
            )

        # Calculate position size BEFORE creating OrderRequest
        equity = self._accounting.get_equity()

        # Get current price for size calculation
        current_price = signal.entry_price or self._regime_detector.get_price(signal.symbol)
        if not current_price or current_price <= 0:
            logger.warning(f"No valid price for {signal.symbol}, skipping signal")
            await self._emit_order_decision(
                signal=signal,
                decision="SKIP",
                reason_code="VALIDATION_FAIL",
                computed_qty=None,
                context={
                    "reason": "missing_price",
                    "open_orders": len(self._order_manager.get_open_orders()),
                    "open_positions": len(self._accounting.get_positions()),
                },
            )
            return

        # Get regime first (needed for size calculation)
        regime = self._current_regime.get(signal.symbol, Regime.NORMAL)

        # Get metrics for dynamic risk scaling (needed for size calculation)
        rolling_pf = None
        recent_drawdown = None
        volatility_percentile = None
        edge_bps = None

        # Get rolling profit factor from strategy metrics
        strategy_metrics = self._accounting.get_strategy_metrics()
        if strategy_metrics:
            signal_metrics = strategy_metrics.get(signal.strategy_id)
            if signal_metrics:
                rolling_pf = signal_metrics.get("profit_factor", 1.0)
            else:
                # Fallback: aggregate PF across all strategies
                total_wins = 0.0
                total_losses = 0.0
                for m in strategy_metrics.values():
                    total_wins += m.get("wins", 0)
                    total_losses += m.get("losses", 0)
                if total_losses > 0:
                    rolling_pf = total_wins / total_losses
                elif total_wins > 0:
                    rolling_pf = total_wins
                else:
                    rolling_pf = 1.0
        else:
            rolling_pf = 1.0

        # Get recent drawdown
        _, drawdown_pct = self._accounting.get_drawdown(equity)
        recent_drawdown = drawdown_pct

        # Get volatility and calculate percentile
        current_volatility = self._regime_detector.get_volatility(signal.symbol)
        if current_volatility > 0:
            # Update volatility history in position sizer
            self._position_sizer.update_volatility(current_volatility)
            # Calculate percentile
            dynamic_risk = self._position_sizer.get_dynamic_risk_manager()
            volatility_percentile = dynamic_risk.calculate_volatility_percentile(current_volatility)

        # Get edge_bps from signal metadata if available
        if signal.metadata:
            edge_bps = signal.metadata.get("edge_bps")

        # Strategy Capital Allocation: use allocated capital instead of total equity
        sizing_equity = equity
        if self._strategy_allocator:
            allocated = self._strategy_allocator.get_allocation(signal.strategy_id)
            if allocated is not None and allocated > 0:
                sizing_equity = allocated
                logger.debug(
                    f"Strategy allocator: {signal.strategy_id} allocated ${allocated:.2f} "
                    f"(of ${equity:.2f} total)"
                )

        # Calculate base size
        base_size = signal.size or self._position_sizer.calculate_size(
            signal,
            sizing_equity,
            current_price,
            regime,
            rolling_pf=rolling_pf,
            recent_drawdown=recent_drawdown,
            volatility_percentile=volatility_percentile,
            edge_bps=edge_bps,
        )

        # Ensure minimum size
        if base_size <= 0:
            min_size_value = (equity * 0.001) / current_price  # 0.1% of equity
            absolute_min = 0.001
            base_size = max(min_size_value, absolute_min)
            logger.warning(f"Base size was 0, using minimum {base_size:.6f}")

        # Physics-Aware Position Sizing: adjust base_size based on market physics
        if self._physics_positioner:
            adjusted = self._physics_positioner.get_physics_adjusted_signal(signal)
            if adjusted is None:
                # Physics blocked the trade (e.g., SSD Silent mode)
                await self._emit_order_decision(
                    signal=signal,
                    decision="REJECT",
                    reason_code="PHYSICS_BLOCK",
                    computed_qty=base_size,
                    context={"note": "Physics-Aware Positioner blocked signal (SSD Silent or extreme entropy)"},
                )
                return
            # Apply the physics size multiplier
            physics_mult = (adjusted.metadata or {}).get("physics_size_mult", 1.0)
            if physics_mult != 1.0:
                base_size *= physics_mult
                logger.debug(f"Physics adjusted size: {physics_mult:.2f}x ‚Üí {base_size:.6f}")

        # Apply protection multiplier
        if protection_size_multiplier < 1.0:
            base_size *= protection_size_multiplier
            if base_size <= 0:
                min_size_value = (equity * 0.001) / current_price
                absolute_min = 0.001
                base_size = max(min_size_value, absolute_min)

        # Check risk limits with calculated size (always active, except pre-approved external risk)
        if not external_risk_approved:
            allowed, reason = self._risk_limits.check_order_request(
                OrderRequest(
                    signal_id=str(uuid.uuid4()),
                    strategy_id=signal.strategy_id,
                    symbol=signal.symbol,
                    side=signal.side,
                    size=base_size,
                    price=signal.entry_price,
                ),
                equity,
            )

            if not allowed:
                logger.debug(f"Signal rejected by risk limits: {reason}")
                reason_code = "RISK_BLOCKED"
                if "Position already exists" in reason:
                    reason_code = "POSITION_EXISTS"
                elif "Max open positions" in reason:
                    reason_code = "RISK_BLOCKED"
                metrics.increment("signals_rejected")
                no_trade_report.increment("risk_limits_reject", signal.symbol, signal.strategy_id)
                no_trade_report.increment_pipeline("signals_rejected_risk", signal.strategy_id)
                log_block_reason(
                    "risk_limits_reject",
                    symbol=signal.symbol,
                    strategy_id=signal.strategy_id,
                    agent_name=signal.strategy_id,
                    threshold=None,
                    measured_value=None,
                )
                log_allow_reason("BLOCK", symbol=signal.symbol, strategy_id=signal.strategy_id, note=f"risk_limits: {reason}")
                await self._emit_order_decision(
                    signal=signal,
                    decision="REJECT",
                    reason_code=reason_code,
                    computed_qty=base_size,
                    context={
                        "equity": equity,
                        "price": current_price,
                        "reason": reason,
                        "open_orders": len(self._order_manager.get_open_orders()),
                        "open_positions": len(self._accounting.get_positions()),
                    },
                )
                return

            # Check daily attempts and cooldown (always active for local signals)
            regime = self._current_regime.get(signal.symbol, Regime.NORMAL)
            allowed, reason = self._risk_limits.check_daily_attempts(signal.strategy_id, regime)
            if not allowed:
                logger.debug(f"Signal rejected: {reason}")
                metrics.increment("signals_rejected")
                no_trade_report.increment(
                    "daily_attempts_reject", signal.symbol, signal.strategy_id
                )
                no_trade_report.increment_pipeline(
                    "signals_rejected_daily_attempts", signal.strategy_id
                )
                log_block_reason(
                    "daily_attempts_reject",
                    symbol=signal.symbol,
                    strategy_id=signal.strategy_id,
                    agent_name=signal.strategy_id,
                )
                log_allow_reason("BLOCK", symbol=signal.symbol, strategy_id=signal.strategy_id, note=f"daily_attempts: {reason}")
                await self._emit_order_decision(
                    signal=signal,
                    decision="SKIP",
                    reason_code="DAILY_LIMIT",
                    computed_qty=base_size,
                    context={
                        "reason": reason,
                        "attempts": self._risk_limits._daily_attempts.get(signal.strategy_id, 0),
                        "regime": regime.value if hasattr(regime, "value") else str(regime),
                        "open_orders": len(self._order_manager.get_open_orders()),
                        "open_positions": len(self._accounting.get_positions()),
                    },
                )
                return

            allowed, reason = self._risk_limits.check_cooldown(signal.strategy_id)
            if not allowed:
                logger.debug(f"Signal rejected: {reason}")
                metrics.increment("signals_rejected")
                no_trade_report.increment("cooldown_reject", signal.symbol, signal.strategy_id)
                no_trade_report.increment_pipeline("signals_rejected_cooldown", signal.strategy_id)
                log_block_reason(
                    "cooldown_reject",
                    symbol=signal.symbol,
                    strategy_id=signal.strategy_id,
                    agent_name=signal.strategy_id,
                )
                log_allow_reason("BLOCK", symbol=signal.symbol, strategy_id=signal.strategy_id, note=f"cooldown: {reason}")
                await self._emit_order_decision(
                    signal=signal,
                    decision="SKIP",
                    reason_code="COOLDOWN",
                    computed_qty=base_size,
                    context={
                        "reason": reason,
                        "consecutive_losses": self._risk_limits.get_consecutive_losses(signal.strategy_id),
                        "open_orders": len(self._order_manager.get_open_orders()),
                        "open_positions": len(self._accounting.get_positions()),
                    },
                )
                return
        else:
            logger.debug(
                "External risk-approved signal received: %s %s %s",
                signal.strategy_id,
                signal.symbol,
                signal.side,
            )

        # ------------------------------------------------------------------
        # Decision Memory: context-aware gating and penalty
        # ------------------------------------------------------------------
        # Get current regime first (needed for context building)
        regime = self._current_regime.get(signal.symbol, Regime.NORMAL)

        # Build context from current regime, approximate spread/vol, and time
        spread_bps = None
        if getattr(signal, "metadata", None):
            # Strategies may pass finer-grained context
            spread_bps = signal.metadata.get("spread_bps")
        volatility = self._regime_detector.get_volatility(signal.symbol)
        context = self._decision_memory.build_context(
            regime=regime,
            spread_bps=spread_bps,
            volatility=volatility,
            timestamp=event.timestamp,
        )

        # Check if context is blocked (always active)
        has_dm_history = self._decision_memory.has_history(signal.strategy_id, context)
        if has_dm_history and self._decision_memory.blocked(signal.strategy_id, context):
            logger.debug(
                "Signal rejected by decision memory: strategy=%s context=%s",
                signal.strategy_id,
                context,
            )
            metrics.increment("signals_rejected")
            no_trade_report.increment(
                "decision_memory_block", signal.symbol, signal.strategy_id
            )
            no_trade_report.increment_pipeline(
                "signals_blocked_decision_memory", signal.strategy_id
            )
            log_block_reason(
                "decision_memory_block",
                symbol=signal.symbol,
                strategy_id=signal.strategy_id,
                agent_name=signal.strategy_id,
            )
            log_allow_reason(
                "BLOCK",
                symbol=signal.symbol,
                strategy_id=signal.strategy_id,
                note="decision_memory",
            )
            await self._emit_order_decision(
                signal=signal,
                decision="SKIP",
                reason_code="DECISION_MEMORY",
                computed_qty=base_size,
                context={
                    "reason": "decision_memory_block",
                    "context": context,
                    "has_history": has_dm_history,
                    "open_orders": len(self._order_manager.get_open_orders()),
                    "open_positions": len(self._accounting.get_positions()),
                },
            )
            return

        # Position size already calculated above, reuse it
        # (variables regime, rolling_pf, recent_drawdown, volatility_percentile, edge_bps already defined)
        logger.info(f"Base size calculated: {base_size:.6f} (signal.size={signal.size}, equity=${equity:.2f}, price=${current_price:.2f})")

        # CRITICAL: If base_size is 0 or negative, use minimum size immediately
        original_base_size = base_size
        if base_size <= 0:
            min_size_value = (equity * 0.001) / current_price  # 0.1% of equity in units
            absolute_min = 0.001
            base_size = max(min_size_value, absolute_min)
            logger.warning(
                f"Base size was {original_base_size:.6f}, using minimum size {base_size:.6f} "
                f"to ensure trading can occur"
            )

        # Apply protection size multiplier
        if protection_size_multiplier < 1.0:
            base_size *= protection_size_multiplier
            logger.debug(f"Position size reduced by protection: {protection_size_multiplier:.2f}x")
            # Ensure base_size doesn't become 0 after protection multiplier
            if base_size <= 0:
                min_size_value = (equity * 0.001) / current_price  # 0.1% of equity in units
                absolute_min = 0.001
                base_size = max(min_size_value, absolute_min)
                logger.warning(
                    f"Base size became 0 after protection multiplier, using minimum {base_size:.6f}"
                )

        # Decision memory penalty
        # Decision memory penalty (always active)
        penalty_multiplier = self._decision_memory.penalty(signal.strategy_id, context)

        size_multiplier = penalty_multiplier
        if getattr(signal, "metadata", None) and "size_multiplier" in signal.metadata:
            try:
                signal_mult = float(signal.metadata["size_multiplier"])
            except (TypeError, ValueError):
                signal_mult = 1.0
            # Combined multiplier, but still never > 1.0
            size_multiplier *= min(signal_mult, 1.0)
        logger.debug(f"Size multiplier after signal metadata: {size_multiplier}")

        if size_multiplier > 1.0:
            size_multiplier = 1.0  # Safety: do not increase risk above base sizing

        size = base_size * size_multiplier
        logger.debug(f"Final size: {size} (base={base_size}, mult={size_multiplier})")

        # CRITICAL FIX: Always ensure minimum size, never reject due to size
        # Calculate minimum size: at least 0.1% of equity worth
        min_size_value = (equity * 0.001) / current_price  # 0.1% of equity in units
        # Also ensure absolute minimum (e.g., 0.001 BTC or equivalent)
        absolute_min = 0.001
        min_size = max(min_size_value, absolute_min)

        if size < min_size:
            logger.warning(
                f"Position size {size:.6f} below minimum {min_size:.6f}, "
                f"using minimum size to allow trading"
            )
            size = min_size
            logger.info(
                f"Using minimum position size {size:.6f} to ensure trades can execute "
                f"(equity=${equity:.2f}, price=${current_price:.2f})"
            )

        if signal.metadata is None:
            signal.metadata = {}

        sizing_details = self._position_sizer.get_last_calculation() or {}
        applied_leverage = max(1.0, float(sizing_details.get("leverage", 1.0)))
        exit_plan = {
            "tp": signal.take_profit,
            "sl": signal.stop_loss,
            "trailing": signal.metadata.get("trailing"),
            "time_stop_seconds": signal.metadata.get("time_stop_seconds")
            or signal.metadata.get("max_time_sec"),
            "invalidation_rule": signal.metadata.get("invalidation_rule"),
        }
        expected_pnl = self._calculate_expected_pnl(
            side=signal.side,
            entry_price=signal.entry_price,
            qty=size,
            take_profit=signal.take_profit,
            stop_loss=signal.stop_loss,
        )
        rationale = {
            "strategy_name": signal.strategy_id,
            "entry_reason": signal.metadata.get("entry_reason")
            or signal.metadata.get("reason")
            or "Strategy signal",
            "confidence": signal.metadata.get("confidence")
            or signal.metadata.get("edge_bps")
            or sizing_details.get("edge_bps"),
        }

        order_metadata = {
            **(signal.metadata or {}),
            "exit_plan": exit_plan,
            "expected_pnl": expected_pnl,
            "rationale": rationale,
            "applied_leverage": applied_leverage,
        }

        # Create order request
        signal_id = str(uuid.uuid4())
        order_request = OrderRequest(
            signal_id=signal_id,
            strategy_id=signal.strategy_id,
            symbol=signal.symbol,
            side=signal.side,
            size=size,
            price=signal.entry_price,
            order_type="market",
            stop_loss=signal.stop_loss,
            take_profit=signal.take_profit,
            metadata=order_metadata,
        )
        order_request.metadata["signal_id"] = signal_id

        # Track order creation
        no_trade_report.increment_pipeline("orders_created", signal.strategy_id)

        # Record attempt
        self._risk_limits.record_attempt(signal.strategy_id)

        # DEBUG: Track signals after filters and order creation
        self._signals_after_filters += 1
        self._orders_sent += 1
        metrics.increment("signals_after_filters_total")
        metrics.increment("orders_sent_total")

        # Log order creation details
        penalties = []
        if size_multiplier < 1.0:
            penalties.append(f"size_mult={size_multiplier:.2f}")
        if protection_size_multiplier < 1.0:
            penalties.append(f"protection_mult={protection_size_multiplier:.2f}")
        if penalty_multiplier < 1.0:
            penalties.append(f"penalty_mult={penalty_multiplier:.2f}")
        penalty_str = ", ".join(penalties) if penalties else "none"
        logger.debug(
            f"Order created: signal_id={order_request.signal_id} strategy={signal.strategy_id} "
            f"symbol={signal.symbol} side={signal.side} size={size:.6f} penalties=[{penalty_str}]"
        )

        # Emit ORDER_DECISION with full sizing context before publishing
        await self._emit_order_decision(
            signal=signal,
            decision="CREATE",
            reason_code="ACCEPTED",
            computed_qty=size,
            context={
                "price": current_price,
                "notional": size * current_price,
                "applied_leverage": applied_leverage,
                "equity": equity,
                "cash": self._accounting.get_cash_balance(),
                "open_orders": len(self._order_manager.get_open_orders()),
                "open_positions": len(self._accounting.get_positions()),
                "exit_plan": exit_plan,
                "expected_pnl": expected_pnl,
                "penalties": penalties,
            },
        )

        # Publish order request
        logger.debug(
            f"Publishing ORDER_REQUEST: {order_request.symbol} {order_request.side} size={order_request.size:.6f}"
        )
        await self._bus.publish(
            Event(
                event_type=EventType.ORDER_REQUEST,
                data={"order_request": order_request},
            )
        )

        metrics.increment("signals_accepted")

        # Final diagnostic: ALLOW
        log_allow_reason(
            "ALLOW",
            symbol=signal.symbol,
            strategy_id=signal.strategy_id,
            note=f"OrderRequest created: size={size:.6f}",
        )

    async def _handle_order_filled(self, event: Event) -> None:
        """Handle order fill event."""
        logger.info("[ORDER_FILLED_HANDLER] Received ORDER_FILLED event")

        # Deduplicate: Bybit sends multiple partial fills for the same order_id.
        # Only process the FIRST fill per order_id to prevent phantom positions.
        if not hasattr(self, "_filled_order_ids"):
            self._filled_order_ids: OrderedDict[str, bool] = OrderedDict()

        raw_order_id = event.data.get("order_id") or (event.data.get("order") and getattr(event.data.get("order"), "order_id", None))
        if raw_order_id and raw_order_id in self._filled_order_ids:
            logger.debug(f"[ORDER_FILLED_HANDLER] Skipping duplicate fill for order {raw_order_id}")
            return
        if raw_order_id:
            self._filled_order_ids[raw_order_id] = True
            # Keep OrderedDict bounded by removing oldest entries
            while len(self._filled_order_ids) > 5000:
                self._filled_order_ids.popitem(last=False)

        # Safe extraction with defaults - try multiple sources
        order = event.data.get("order")
        fill_price_raw = event.data.get("fill_price", 0.0)
        fill_size_raw = event.data.get("fill_size", 0.0)

        if not order:
            order_id = event.data.get("order_id")
            if order_id:
                # Try order_manager first to get strategy_id/symbol
                managed = self._order_manager.get_order(order_id)
                # Always construct a FILLED order with actual fill data
                order = Order(
                    order_id=order_id,
                    strategy_id=managed.strategy_id if managed else event.data.get("strategy_id", "unknown"),
                    symbol=managed.symbol if managed else event.data.get("symbol", "UNKNOWN"),
                    side=(managed.side if managed else event.data.get("side", "buy")).lower(),
                    size=fill_size_raw or (managed.size if managed else 0.0),
                    filled_size=fill_size_raw or (managed.size if managed else 0.0),
                    price=fill_price_raw,
                    avg_fill_price=fill_price_raw,
                    order_type=managed.order_type if managed else "limit",
                    status=OrderStatus.FILLED,
                    timestamp=datetime.utcnow(),
                    stop_loss=managed.stop_loss if managed else None,
                    take_profit=managed.take_profit if managed else None,
                    metadata=managed.metadata if managed else event.data.get("metadata", {}),
                )
                logger.info(f"[ORDER_FILLED_HANDLER] Built filled order: {order_id} {order.side} {order.filled_size} {order.symbol} @ {fill_price_raw}")
            else:
                logger.warning(f"[ORDER_FILLED_HANDLER] Missing order_id in event data: {event.data}")
                return

        fill_price = event.data.get("fill_price", 0.0)
        event.data.get("fill_size", 0.0)
        fee = event.data.get("fee", 0.0)

        logger.info(
            f"[ORDER_FILLED_HANDLER] Processing order {order.order_id}: "
            f"status={order.status}, filled_size={order.filled_size}, "
            f"size={order.size}, fill_price={fill_price:.2f}, fee={fee:.4f}"
        )

        # Fabric: spawn ORDER_FILLED DNA from event's parent DNA (if present)
        if self._fabric_registry is not None:
            parent_dna = extract_dna(event)
            if parent_dna:
                fill_dna = self._fabric_registry.spawn(parent_dna.event_id, event)
            else:
                fill_dna = self._fabric_registry.register(event)
            inject_dna(event, fill_dna)

        # DEBUG: Track order fills
        self._orders_filled += 1
        metrics.increment("orders_filled_total")

        # Record trade for density tracking
        trade_density.record_trade(order.strategy_id, event.timestamp)

        # Update accounting (cash adjustment for the fill)
        self._accounting.record_fill(order, fill_price, fee)
        logger.info(f"[ORDER_FILLED_HANDLER] Accounting updated for order {order.order_id}")

        # Re-publish ORDER_FILLED on EventBus for downstream listeners
        # (feedback_agent, API stream, execution routers, global_sync)
        await self._bus.publish(
            Event(
                event_type=EventType.ORDER_FILLED,
                data={
                    "order": order,
                    "fill_price": fill_price,
                    "fill_size": event.data.get("fill_size", order.qty),
                    "fee": fee,
                    "symbol": order.symbol,
                    "side": order.side,
                    "strategy_id": order.strategy_id,
                },
            )
        )

        # Detect close fills: check if this fill reduces an existing position
        # A close fill occurs when we have a position and the fill is on the opposite side
        is_close_fill = False
        closing_position = None

        # Check metadata first (our own close orders)
        if order.metadata and order.metadata.get("is_close"):
            is_close_fill = True

        # Check Bybit closedSize indicator
        if event.data.get("closedSize") or event.data.get("reduce_only"):
            is_close_fill = True

        # Heuristic: if we have an existing position for this symbol on the opposite side
        if not is_close_fill:
            fill_side = "long" if order.side == "buy" else "short"
            for pos in self._accounting.get_positions():
                if pos.symbol == order.symbol and pos.side != fill_side:
                    is_close_fill = True
                    break

        if is_close_fill:
            # Find the position being closed
            for pos in self._accounting.get_positions():
                if pos.symbol == order.symbol:
                    closing_position = pos
                    break

            if closing_position:
                # Calculate realized PnL
                if closing_position.side == "long":
                    realized_pnl = (fill_price - closing_position.entry_price) * closing_position.size
                else:
                    realized_pnl = (closing_position.entry_price - fill_price) * closing_position.size

                closing_position.current_price = fill_price
                closing_position.realized_pnl = realized_pnl

                logger.info(
                    f"[ORDER_FILLED_HANDLER] Close fill detected: closing {closing_position.position_id} "
                    f"({closing_position.symbol} {closing_position.side}) PnL={realized_pnl:.4f}"
                )

                await self._bus.publish(
                    Event(
                        event_type=EventType.POSITION_CLOSED,
                        data={
                            "position": closing_position,
                            "close_reason": "exchange_fill",
                            "exchange_close": True,
                        },
                    )
                )
                metrics.increment("positions_closed")
            else:
                logger.warning(
                    f"[ORDER_FILLED_HANDLER] Close fill for {order.symbol} but no matching position found"
                )

            await self._emit_account_state()
            return

        # Open fill: Create position if fully filled
        if order.status == OrderStatus.FILLED and order.avg_fill_price:
            logger.info(
                f"[ORDER_FILLED_HANDLER] Order {order.order_id} is fully filled, "
                f"creating position: avg_fill_price={order.avg_fill_price:.2f}"
            )
            take_profit_1 = None
            if "take_profit_1" in order.metadata:
                take_profit_1 = order.metadata["take_profit_1"]

            position = Position(
                position_id=str(uuid.uuid4()),
                symbol=order.symbol,
                side="long" if order.side == "buy" else "short",
                size=order.filled_size,
                entry_price=order.avg_fill_price,
                current_price=order.avg_fill_price,
                opened_at=order.timestamp,
                strategy_id=order.strategy_id,
                stop_loss=order.stop_loss,
                take_profit=order.take_profit,
                take_profit_1=take_profit_1,
                max_time_sec=(
                    settings.impulse_max_time_in_trade_sec
                    if order.strategy_id == "impulse_engine"
                    else None
                ),
                metadata=order.metadata or {},
            )

            self._accounting.add_position(position)
            self._risk_limits.register_position(position)
            logger.info(
                f"[ORDER_FILLED_HANDLER] Position {position.position_id} created and registered: "
                f"{position.side} {position.size} {position.symbol} @ {position.entry_price:.2f}"
            )

            pos_event = Event(
                event_type=EventType.POSITION_OPENED,
                data={"position": position},
            )
            # Fabric: propagate DNA from fill ‚Üí POSITION_OPENED
            if self._fabric_registry is not None:
                fill_parent = extract_dna(event)
                if fill_parent:
                    pos_dna = self._fabric_registry.spawn(fill_parent.event_id, pos_event)
                else:
                    pos_dna = self._fabric_registry.register(pos_event)
                inject_dna(pos_event, pos_dna)
                # Store DNA IDs in position metadata for retrieval at POSITION_CLOSED
                if position.metadata is None:
                    position.metadata = {}
                position.metadata["_fabric_trace_id"] = pos_dna.trace_id
                position.metadata["_fabric_event_id"] = pos_dna.event_id
            await self._bus.publish(pos_event)

            metrics.increment("positions_opened")
            no_trade_report.increment_pipeline("positions_opened", order.strategy_id)

            # Exchange-side SL/TP
            if order.stop_loss or order.take_profit:
                try:
                    bybit_http = getattr(self._execution_router, "_bybit_http", None)
                    if bybit_http:
                        await bybit_http.set_trading_stop(
                            symbol=order.symbol,
                            stop_loss=order.stop_loss,
                            take_profit=order.take_profit,
                        )
                        logger.info(
                            f"[EXCHANGE PROTECTION] SL/TP set on Bybit for {order.symbol}: "
                            f"SL={order.stop_loss}, TP={order.take_profit}"
                        )
                except Exception as e:
                    logger.error(
                        f"[EXCHANGE PROTECTION] Failed to set SL/TP on Bybit for "
                        f"{order.symbol}: {e}. PositionMonitor still active as fallback."
                    )
        else:
            logger.warning(
                f"[ORDER_FILLED_HANDLER] Order {order.order_id} not fully filled or missing avg_fill_price: "
                f"status={order.status}, avg_fill_price={order.avg_fill_price}"
            )
        await self._emit_account_state()

    async def _handle_position_closed(self, event: Event) -> None:
        """Handle position closed event."""
        position = event.data.get("position")
        if not position:
            logger.warning(f"[POSITION_CLOSED] Missing 'position' in event data: {event.data}")
            return
        self._accounting.remove_position(position.position_id)
        self._risk_limits.unregister_position(position.position_id)

        # Record win/loss
        if position.realized_pnl > 0:
            self._risk_limits.record_win(position.strategy_id)
        else:
            self._risk_limits.record_loss(position.strategy_id)

        # Record realized PnL per strategy and regime
        regime = self._current_regime.get(position.symbol, Regime.NORMAL)
        self._accounting.record_realized_pnl(
            position.realized_pnl, position.strategy_id, regime.value
        )

        # Build context key for decision memory
        spread_bps = None
        volatility = None
        if position.metadata:
            spread_bps = position.metadata.get("spread_bps")
            volatility = position.metadata.get("volatility")

        # Get volatility from regime detector if not in metadata
        if volatility is None:
            volatility = self._regime_detector.get_volatility(position.symbol)

        context_key = self._decision_memory.build_context(
            regime=regime,
            spread_bps=spread_bps,
            volatility=volatility,
            timestamp=event.timestamp,
        )

        # Record close with new API
        self._decision_memory.record_close(
            strategy_id=position.strategy_id,
            context_key=context_key,
            pnl=position.realized_pnl,
            timestamp=event.timestamp,
        )

        # Record profit in profit target tracker
        self._profit_tracker.record_profit(position.realized_pnl)

        # –£–ú–ù–ê–Ø –†–ï–ò–ù–í–ï–°–¢–ò–¶–ò–Ø –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π –ø—Ä–∏–±—ã–ª—å–Ω–æ–π —Å–¥–µ–ª–∫–∏
        if position.realized_pnl > 0:
            profit = position.realized_pnl
            current_equity = self._accounting.get_equity()
            initial_capital = self._accounting.initial_capital
            _, drawdown_pct = self._accounting.get_drawdown(current_equity)

            # –ü–æ–ª—É—á–∏—Ç—å rolling PF –¥–ª—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
            strategy_metrics = self._accounting.get_strategy_metrics()
            rolling_pf = 1.0
            if strategy_metrics and position.strategy_id in strategy_metrics:
                rolling_pf = strategy_metrics[position.strategy_id].get("profit_factor", 1.0)

            # –†–∞—Å—Å—á–∏—Ç–∞—Ç—å —É–º–Ω—É—é —Ä–µ–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏—é
            reinvestor = SmartReinvestor()
            reinvest_amount = reinvestor.calculate_smart_reinvestment(
                profit=profit,
                current_equity=current_equity,
                initial_capital=initial_capital,
                drawdown_pct=drawdown_pct,
                rolling_pf=rolling_pf,
            )

            # –ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ —Ä–µ–∏–Ω–≤–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å
            if reinvest_amount > 0:
                self._accounting.update_cash(reinvest_amount)
                logger.info(
                    f"SMART REINVESTMENT: Profit=${profit:.2f}, "
                    f"Reinvest=${reinvest_amount:.2f} ({reinvest_amount / profit * 100:.1f}%), "
                    f"New Equity=${self._accounting.get_equity():.2f}, "
                    f"Drawdown={drawdown_pct:.1f}%, PF={rolling_pf:.2f}"
                )

        # Fabric: complete causal chain and credit EEV with realized PnL
        if self._fabric_registry is not None and self._fabric_eev is not None:
            # Recover event_id from position metadata (stored at POSITION_OPENED)
            fabric_event_id = (position.metadata or {}).get("_fabric_event_id")
            if fabric_event_id:
                # Get lineage before completing (complete_chain doesn't return it)
                pos_dna = self._fabric_registry._registry.get(fabric_event_id)
                lineage = pos_dna.lineage if pos_dna else []
                # Complete chain with outcome
                self._fabric_registry.complete_chain(
                    fabric_event_id,
                    {"pnl": position.realized_pnl, "symbol": position.symbol},
                )
                # Credit EEV with depth-decayed PnL across all ancestor fingerprints
                if lineage:
                    phase = regime.value if regime else "*"
                    credited = self._fabric_eev.credit_chain(
                        lineage, position.symbol, position.realized_pnl,
                        metadata={"phase": phase},
                    )
                    logger.debug(
                        f"[FABRIC] Chain completed: event={fabric_event_id[:8]}‚Ä¶ "
                        f"lineage={lineage} pnl={position.realized_pnl:.4f} "
                        f"credited={credited} fingerprints"
                    )

        metrics.increment("positions_closed")
        no_trade_report.increment_pipeline("positions_closed", position.strategy_id)
        await self._emit_account_state()

    async def _handle_stop_trading(self, event: Event) -> None:
        """Handle stop trading event."""
        reason = event.data.get("reason", "Unknown")
        logger.warning(f"Stop trading triggered: {reason}")
        self._stop_trading = True
        if self._risk_sentinel:
            self._risk_sentinel.set_stop_trading(True)

    async def _handle_killswitch(self, event: Event) -> None:
        """Handle killswitch triggered event."""
        reason = event.data.get("reason", "Unknown")
        logger.critical(f"Killswitch triggered: {reason}")
        self._stop_trading = True
        if self._risk_sentinel:
            self._risk_sentinel.set_stop_trading(True)

    async def _handle_killswitch_reset(self, event: Event) -> None:
        """Handle killswitch reset event ‚Äî resume trading."""
        reset_type = event.data.get("reset_type", "unknown")
        prev_reason = event.data.get("previous_reason", "Unknown")
        logger.info(
            f"Killswitch reset ({reset_type}), resuming trading. "
            f"Previous reason: {prev_reason}"
        )
        self._stop_trading = False
        if self._risk_sentinel:
            self._risk_sentinel.set_stop_trading(False)

    async def _handle_position_close_request(self, event: Event) -> None:
        """Handle POSITION_CLOSE_REQUEST from Oracle or other modules.

        Routes close requests to ExecutionRouter to actually close positions.
        """
        position_id = event.data.get("position_id")
        reason = event.data.get("reason", "external_close_request")
        if not position_id:
            logger.warning("[CLOSE_REQUEST] Missing position_id in event data")
            return

        # Find the position
        position = None
        for p in self._accounting.get_positions():
            if p.position_id == position_id:
                position = p
                break

        if not position:
            logger.warning(f"[CLOSE_REQUEST] Position {position_id} not found")
            return

        logger.info(f"[CLOSE_REQUEST] Closing position {position_id} reason={reason}")
        price = (
            self._execution_router._current_prices.get(position.symbol)
            if hasattr(self._execution_router, "_current_prices")
            else None
        )
        price = price or position.current_price or position.entry_price
        await self._close_position_at_price(position, price, reason=reason)

    async def _handle_meta_learning_patch(self, event: Event) -> None:
        """Handle META_LEARNING_PATCH ‚Äî apply parameter updates to strategies."""
        patch = event.data.get("patch", {})
        strategy_id = event.data.get("strategy_id")
        if not patch:
            return

        applied = False
        for strategy in self._strategies:
            if strategy_id and strategy.strategy_id != strategy_id:
                continue
            # Apply patch parameters to strategy
            for key, value in patch.items():
                if hasattr(strategy, key):
                    old_val = getattr(strategy, key)
                    setattr(strategy, key, value)
                    logger.info(
                        f"[META_LEARNING] {strategy.strategy_id}.{key}: {old_val} -> {value}"
                    )
                    applied = True

        if applied:
            await self._bus.publish(Event(
                event_type=EventType.STRATEGY_PARAMS_UPDATED,
                data={"strategy_id": strategy_id, "patch": patch, "source": "meta_learning"},
            ))

    async def panic_close_all(self, reason: str = "panic_close_all") -> dict[str, Any]:
        """Force-close all positions and cancel open orders (paper-safe)."""
        closed_positions: list[str] = []
        for position in list(self._accounting.get_positions()):
            price = (
                self._execution_router._current_prices.get(position.symbol)
                if hasattr(self._execution_router, "_current_prices")
                else None
            )
            price = price or position.current_price or position.entry_price
            await self._emit_order_exit_decision(
                position=position,
                decision="FORCE_CLOSE",
                reason_code="RISK_EXIT",
                tick_price=price,
                thresholds={
                    "tp": position.take_profit,
                    "sl": position.stop_loss,
                    "time_stop_seconds": position.max_time_sec or settings.max_hold_seconds,
                },
                hold_seconds=(datetime.utcnow() - position.opened_at).total_seconds()
                if position.opened_at
                else None,
                note=reason,
            )
            await self._close_position_at_price(position, price, reason=reason)
            closed_positions.append(position.position_id)

        # Cancel open orders
        for order in self._order_manager.get_open_orders():
            order.status = OrderStatus.CANCELLED
            await self._bus.publish(
                Event(
                    event_type=EventType.ORDER_CANCELLED,
                    data={"order": order},
                )
            )

        await self._emit_account_state()
        return {"closed_positions": len(closed_positions), "cancelled_orders": len(self._order_manager.get_open_orders())}

    async def reset_paper_state(self) -> dict[str, Any]:
        """Clear paper-trading state (positions, orders, cached decisions)."""
        # Remove positions
        for pos in list(self._accounting.get_positions()):
            self._accounting.remove_position(pos.position_id)

        # Reset orders
        self._order_manager._orders.clear()
        self._order_manager._orders_by_strategy.clear()
        self._order_manager._orders_by_symbol.clear()

        # Reset diagnostics / histories
        self._order_exit_decision_history.clear()
        self._order_decision_history.clear()
        self._last_exit_decision_ts.clear()
        self._last_tick_at.clear()

        # Reset killswitch and stop_trading
        if hasattr(self, "_killswitch"):
            await self._killswitch.reset()
            logger.info("Killswitch reset via reset_paper_state")
        self._stop_trading = False
        logger.info("Stop trading flag reset via reset_paper_state")

        await self._emit_account_state()
        return {"status": "reset", "positions": 0, "orders": 0}

    def _calculate_expected_pnl(
        self,
        side: str,
        entry_price: float,
        qty: float,
        take_profit: float | None,
        stop_loss: float | None,
    ) -> dict[str, float | None]:
        """Calculate expected PnL at TP/SL for telemetry."""
        if entry_price is None or qty <= 0:
            return {"at_tp": None, "at_sl": None, "breakeven_price": None, "rr_ratio": None}

        at_tp = None
        at_sl = None

        if take_profit is not None:
            if side == "buy":
                at_tp = (take_profit - entry_price) * qty
            else:
                at_tp = (entry_price - take_profit) * qty

        if stop_loss is not None:
            if side == "buy":
                at_sl = (stop_loss - entry_price) * qty
            else:
                at_sl = (entry_price - stop_loss) * qty

        rr_ratio = None
        if at_tp is not None and at_sl not in (None, 0):
            try:
                rr_ratio = abs(at_tp / abs(at_sl))
            except ZeroDivisionError:
                rr_ratio = None

        fee_rate = settings.backtest_taker_fee or 0.0
        direction = 1 if side == "buy" else -1
        breakeven_price = entry_price + (entry_price * fee_rate * 2 * direction)

        return {
            "at_tp": at_tp,
            "at_sl": at_sl,
            "breakeven_price": breakeven_price,
            "rr_ratio": rr_ratio,
        }

    def _build_trading_state(self) -> dict[str, Any]:
        """Build unified trading state snapshot for UI/telemetry."""
        mark_prices = getattr(self._execution_router, "_current_prices", {})
        positions_payload: list[dict[str, Any]] = []
        orders_payload: list[dict[str, Any]] = []
        used_margin = 0.0
        reserved_margin = 0.0

        # Positions
        for pos in self._accounting.get_positions():
            mark_price = mark_prices.get(pos.symbol, pos.current_price)
            if mark_price:
                self._accounting.update_position_price(pos.position_id, mark_price)
            metadata = pos.metadata or {}
            try:
                leverage = max(1.0, float(metadata.get("applied_leverage", 1.0)))
            except (TypeError, ValueError):
                leverage = 1.0
            notional = (mark_price or pos.entry_price) * pos.size
            margin_used = notional / leverage if leverage else notional
            used_margin += margin_used
            exit_plan = metadata.get("exit_plan") or {
                "tp": pos.take_profit,
                "sl": pos.stop_loss,
                "trailing": metadata.get("trailing"),
                "time_stop_seconds": metadata.get("max_time_sec"),
                "invalidation_rule": metadata.get("invalidation_rule"),
            }
            positions_payload.append(
                {
                    "position_id": pos.position_id,
                    "symbol": pos.symbol,
                    "side": pos.side,
                    "qty": pos.size,
                    "entry_price": pos.entry_price,
                    "mark_price": mark_price,
                    "unrealized_pnl": pos.unrealized_pnl,
                    "realized_pnl": pos.realized_pnl,
                    "leverage": leverage,
                    "margin_used": margin_used,
                    "opened_at": pos.opened_at.isoformat() if pos.opened_at else None,
                    "exit_plan": exit_plan,
                    "expected_pnl": metadata.get("expected_pnl"),
                    "strategy_id": pos.strategy_id,
                    "status": "open",
                    "rationale": metadata.get("rationale"),
                }
            )

        # Orders (all known states)
        all_orders = self._order_manager.get_all_orders()
        for order in all_orders:
            metadata = order.metadata or {}
            status_value = order.status.value if hasattr(order.status, "value") else str(
                order.status
            )
            mark_price = mark_prices.get(order.symbol, order.price)
            notional = (mark_price or order.price or 0.0) * order.size
            try:
                leverage = max(1.0, float(metadata.get("applied_leverage", 1.0)))
            except (TypeError, ValueError):
                leverage = 1.0
            if order.status in {
                OrderStatus.PENDING,
                OrderStatus.PLACED,
                OrderStatus.PARTIALLY_FILLED,
            }:
                reserved_margin += notional / leverage if leverage else notional

            orders_payload.append(
                {
                    "order_id": order.order_id,
                    "symbol": order.symbol,
                    "side": order.side,
                    "type": order.order_type,
                    "qty": order.size,
                    "price": order.price,
                    "status": status_value,
                    "created_at": order.timestamp.isoformat(),
                    "updated_at": datetime.utcnow().isoformat(),
                    "filled_qty": order.filled_size,
                    "avg_fill_price": order.avg_fill_price,
                    "fee": metadata.get("fee"),
                    "strategy_id": order.strategy_id,
                    "signal_id": metadata.get("signal_id"),
                    "rationale": metadata.get("rationale"),
                    "exit_plan": metadata.get("exit_plan"),
                    "expected_pnl": metadata.get("expected_pnl"),
                    "status_timeline": metadata.get("status_timeline", []),
                }
            )

        unrealized_total = self._accounting.get_unrealized_pnl_total()
        equity_value = self._accounting.get_equity(mark_prices)

        # Use equity as wallet_balance since accounting already includes all positions
        # Don't add used_margin - it's already accounted for in equity calculation
        wallet_balance = equity_value
        available_balance = equity_value - used_margin - reserved_margin

        account_state = {
            "wallet_balance": wallet_balance,
            "available_balance": max(0.0, available_balance),  # Prevent negative available
            "equity": equity_value,
            "used_margin": used_margin,
            "reserved_margin": reserved_margin,
            "unrealized_pnl": unrealized_total,
            "realized_pnl": self._accounting.get_realized_pnl_total(),
            "fees": self._accounting.get_total_fees(),
            "fees_24h": self._accounting.get_total_fees(),
            "timestamp": datetime.utcnow().isoformat(),
        }

        return {
            "account_state": account_state,
            "positions": positions_payload,
            "orders": orders_payload,
        }

    async def _emit_account_state(self) -> None:
        """Publish account/position state for UI and monitoring."""
        snapshot = self._build_trading_state()
        await self._bus.publish(
            Event(
                event_type=EventType.PNL_UPDATE,
                data=snapshot,
            )
        )
        # Also publish EQUITY_UPDATE for risk/strategy listeners
        # (RLRiskManager, StrategyManager subscribe to this)
        account = snapshot.get("account_state", {})
        await self._bus.publish(
            Event(
                event_type=EventType.EQUITY_UPDATE,
                data={
                    "equity": account.get("equity", 0.0),
                    "available_balance": account.get("available_balance", 0.0),
                    "unrealized_pnl": account.get("unrealized_pnl", 0.0),
                    "daily_pnl": account.get("daily_pnl", 0.0),
                },
            )
        )

    async def _handle_tick_forced_exit(self, event: Event) -> None:
        """Mark-to-market on every tick and evaluate exit plans/TTL."""
        tick = event.data["tick"]
        symbol = tick.symbol
        now = datetime.utcnow()
        self._last_tick_at[symbol] = now

        # Fabric: register DNA root for this TICK and cache per-symbol
        if self._fabric_registry is not None:
            dna = self._fabric_registry.register(event)
            inject_dna(event, dna)
            self._fabric_tick_dna[symbol] = dna

        # Mark-to-market update for open positions on this symbol
        for position in self._accounting.get_positions():
            if position.symbol == symbol:
                self._accounting.update_position_price(position.position_id, tick.price)

        # Broadcast fresh account snapshot (PnL_UPDATE for UI/exit triggers)
        await self._emit_account_state()

        # Evaluate exits for positions on this symbol
        for position in list(self._accounting.get_positions()):
            if position.symbol != symbol:
                continue
            await self._evaluate_exit_for_position(position, tick, now)

    async def _evaluate_exit_for_position(
        self,
        position: Position,
        tick: Tick,
        now: datetime | None = None,
    ) -> None:
        """Evaluate TP/SL/TTL for a position and emit exit telemetry."""
        now = now or datetime.utcnow()
        metadata = position.metadata or {}
        exit_plan = metadata.get("exit_plan") or {
            "tp": position.take_profit,
            "sl": position.stop_loss,
            "trailing": metadata.get("trailing"),
            "time_stop_seconds": metadata.get("max_time_sec"),
            "invalidation_rule": metadata.get("invalidation_rule"),
        }

        tp = exit_plan.get("tp") or position.take_profit
        sl = exit_plan.get("sl") or position.stop_loss
        time_stop = exit_plan.get("time_stop_seconds") or position.max_time_sec

        # Paper-assist micro trades may specify max_time_min (minutes)
        if metadata.get("micro_trade"):
            if time_stop is None:
                max_time_min = metadata.get(
                    "max_time_min", settings.paper_trade_assist_micro_trade_max_time_min
                )
                time_stop = max_time_min * 60

        # Global anti-stuck TTL
        if time_stop is None:
            time_stop = settings.max_hold_seconds

        hold_seconds = None
        if position.opened_at:
            hold_seconds = (now - position.opened_at).total_seconds()

        # Use best available price
        price = (
            tick.price
            or self._execution_router._current_prices.get(position.symbol)
            or position.current_price
            or position.entry_price
        )

        thresholds = {
            "tp": tp,
            "sl": sl,
            "time_stop_seconds": time_stop,
        }

        # Exit plan missing guard
        if tp is None and sl is None and time_stop is None:
            await self._emit_order_exit_decision(
                position=position,
                decision="HOLD",
                reason_code="EXIT_PLAN_MISSING",
                tick_price=price,
                thresholds=thresholds,
                hold_seconds=hold_seconds,
                note="No TP/SL/TTL configured",
            )
            return

        # TTL enforcement
        if time_stop and hold_seconds is not None and hold_seconds >= time_stop:
            await self._emit_order_exit_decision(
                position=position,
                decision="FORCE_CLOSE",
                reason_code="TIMEOUT_TTL",
                tick_price=price,
                thresholds=thresholds,
                hold_seconds=hold_seconds,
            )
            await self._close_position_at_price(position, price, reason="timeout_ttl")
            return

        # Take-profit checks
        if tp is not None:
            if position.side == "long" and price >= tp:
                await self._emit_order_exit_decision(
                    position=position,
                    decision="CLOSE",
                    reason_code="TP_HIT",
                    tick_price=price,
                    thresholds=thresholds,
                    hold_seconds=hold_seconds,
                )
                await self._close_position_at_price(position, tp, reason="take_profit")
                return
            if position.side == "short" and price <= tp:
                await self._emit_order_exit_decision(
                    position=position,
                    decision="CLOSE",
                    reason_code="TP_HIT",
                    tick_price=price,
                    thresholds=thresholds,
                    hold_seconds=hold_seconds,
                )
                await self._close_position_at_price(position, tp, reason="take_profit")
                return

        # Stop-loss checks
        if sl is not None:
            if position.side == "long" and price <= sl:
                await self._emit_order_exit_decision(
                    position=position,
                    decision="CLOSE",
                    reason_code="SL_HIT",
                    tick_price=price,
                    thresholds=thresholds,
                    hold_seconds=hold_seconds,
                )
                await self._close_position_at_price(position, sl, reason="stop_loss")
                return
            if position.side == "short" and price >= sl:
                await self._emit_order_exit_decision(
                    position=position,
                    decision="CLOSE",
                    reason_code="SL_HIT",
                    tick_price=price,
                    thresholds=thresholds,
                    hold_seconds=hold_seconds,
                )
                await self._close_position_at_price(position, sl, reason="stop_loss")
                return

        # Nothing to do -> emit throttled HOLD
        last_ts = self._last_exit_decision_ts.get(position.position_id)
        if not last_ts or (now - last_ts).total_seconds() >= 2:
            await self._emit_order_exit_decision(
                position=position,
                decision="HOLD",
                reason_code="HOLD",
                tick_price=price,
                thresholds=thresholds,
                hold_seconds=hold_seconds,
            )
            self._last_exit_decision_ts[position.position_id] = now

    async def _micro_trade_fallback_loop(self) -> None:
        """Deprecated: micro-trade fallback disabled. System uses Bybit testnet directly."""
        logger.warning(
            "[DEPRECATED] _micro_trade_fallback_loop is disabled. "
            "System operates on Bybit testnet ‚Äî no paper trading fallback needed."
        )
        return

    async def _check_position_timeouts(self) -> None:
        """Periodic safety check for stale ticks and TTL enforcement."""
        if not self._running:
            return

        now = datetime.utcnow()
        positions = list(self._accounting.get_positions())
        for position in positions:
            last_tick = self._last_tick_at.get(position.symbol)
            stale = last_tick is None or (now - last_tick).total_seconds() > 3
            if stale:
                price = (
                    self._execution_router._current_prices.get(position.symbol)
                    if hasattr(self._execution_router, "_current_prices")
                    else None
                )
                price = price or position.current_price or position.entry_price
                thresholds = {
                    "tp": position.take_profit,
                    "sl": position.stop_loss,
                    "time_stop_seconds": position.max_time_sec or settings.max_hold_seconds,
                }
                # Emit NO_TICKS hold event (throttled via _evaluate_exit_for_position)
                synthetic_tick = Tick(
                    symbol=position.symbol,
                    price=price,
                    timestamp=now,
                    volume=0.0,
                )
                await self._emit_order_exit_decision(
                    position=position,
                    decision="HOLD",
                    reason_code="NO_TICKS",
                    tick_price=price,
                    thresholds=thresholds,
                    hold_seconds=(now - position.opened_at).total_seconds()
                    if position.opened_at
                    else None,
                    note="No recent market ticks; using last known price",
                )
                # Re-evaluate exits/TTL using synthetic tick to prevent stuck positions
                await self._evaluate_exit_for_position(position, synthetic_tick, now)

        # Emit refreshed account state so UI sees updated unrealized PnL
        await self._emit_account_state()

    async def _close_position_at_price(
        self,
        position: Position,
        close_price: float,
        reason: str = "forced_exit",
    ) -> None:
        """Close a position at a specific price."""
        close_side = "sell" if position.side == "long" else "buy"
        exchange_close = False

        # Send close order to Bybit BEFORE updating internal accounting
        if not settings.dry_run and settings.is_live:
            if hasattr(self._execution_router, "_bybit_http") and self._execution_router._bybit_http:
                try:
                    close_request = OrderRequest(
                        signal_id=f"close_{position.position_id}_{int(datetime.utcnow().timestamp())}",
                        symbol=position.symbol,
                        side=close_side,
                        size=position.size,
                        order_type="market",
                        strategy_id=position.strategy_id,
                        reduce_only=True,
                        metadata={"is_close": True, "position_id": position.position_id},
                    )

                    logger.info(f"Closing position on Bybit: {position.position_id} ({position.symbol} {position.side} {position.size}) - {reason}")
                    await self._execution_router._bybit_http.place_order(close_request)
                    logger.info(f"Successfully closed position on Bybit: {position.position_id}")
                    exchange_close = True
                    # On live: ORDER_FILLED will fire from WS ‚Üí record_fill adjusts cash
                    # We still proceed to update internal state below

                except Exception as e:
                    logger.critical(
                        f"FAILED TO CLOSE POSITION ON BYBIT: {position.position_id} ({position.symbol}) - {e}. "
                        f"Position remains open on exchange! Manual intervention required."
                    )
                    return

        # Update position price
        self._accounting.update_position_price(position.position_id, close_price)

        # Calculate realized PnL
        if position.side == "long":
            realized_pnl = (close_price - position.entry_price) * position.size
        else:  # short
            realized_pnl = (position.entry_price - close_price) * position.size

        # Paper mode: simulate sell proceeds in cash (record_fill won't run)
        if not exchange_close:
            notional = close_price * position.size
            est_fee = notional * 0.00055  # Bybit taker fee
            if close_side == "sell":
                self._accounting.update_cash(notional - est_fee)
            else:
                self._accounting.update_cash(-(notional + est_fee))

        position.current_price = close_price
        position.realized_pnl = realized_pnl

        # Publish position closed event with exchange_close flag
        await self._bus.publish(
            Event(
                event_type=EventType.POSITION_CLOSED,
                data={
                    "position": position,
                    "close_reason": reason,
                    "exchange_close": exchange_close,
                },
            )
        )

    async def _handle_regime_update(self, event: Event) -> None:
        """Handle regime update event."""
        symbol = event.data.get("symbol")
        regime = event.data.get("regime")
        if symbol is None or regime is None:
            logger.warning("REGIME_UPDATE missing symbol/regime: %s", event.data)
            return
        self._current_regime[symbol] = regime
        logger.debug(f"Regime updated: {symbol} -> {regime.value}")

    async def _print_status(self) -> None:
        """Print periodic status update."""
        if not self._running:
            return

        # Get current prices (simplified - would get from price feed)
        current_prices: dict[str, float] = {}
        for pos in self._accounting.get_positions():
            if pos.symbol not in current_prices:
                # Use entry price as proxy (in real system, get from feed)
                current_prices[pos.symbol] = pos.current_price

        snapshot = self._accounting.snapshot(current_prices)

        # Check killswitch ‚Äî use REAL Bybit equity to avoid phantom position inflation.
        # Internal PortfolioAccounting can have inflated equity from duplicate fills.
        equity = snapshot.equity
        if settings.is_live and not settings.dry_run:
            try:
                from hean.api.routers.engine import _fetch_bybit_balance
                bybit_bal = await _fetch_bybit_balance()
                if bybit_bal and bybit_bal.get("equity", 0) > 0:
                    real_equity = bybit_bal["equity"]
                    logger.debug(f"Killswitch using Bybit equity: ${real_equity:.2f} (internal: ${equity:.2f})")
                    equity = real_equity
            except Exception as e:
                logger.debug(f"Bybit equity fetch failed for killswitch: {e}")
        # Use initial_capital as peak to avoid inflated peak from phantom positions
        peak_equity = max(settings.initial_capital or 10000.0, equity)
        # Get regime for killswitch check (use first symbol's regime or NORMAL)
        regime = Regime.NORMAL
        if self._current_regime:
            regime = list(self._current_regime.values())[0]

        # Get strategy metrics first (needed for killswitch check)
        strategy_metrics = self._accounting.get_strategy_metrics()

        # Get rolling PF for killswitch
        rolling_pf = None
        if strategy_metrics:
            total_wins = sum(m.get("wins", 0) for m in strategy_metrics.values())
            total_losses = sum(m.get("losses", 0) for m in strategy_metrics.values())
            if total_losses > 0:
                rolling_pf = total_wins / total_losses
            elif total_wins > 0:
                rolling_pf = total_wins
        await self._killswitch.check_drawdown(equity, peak_equity, regime, rolling_pf)

        # Update strategy equity tracking
        for pos in self._accounting.get_positions():
            strategy_equity = pos.current_price * pos.size + pos.unrealized_pnl
            self._accounting.update_strategy_equity(pos.strategy_id, strategy_equity)

        # Update adaptive capital allocation (daily)
        if strategy_metrics:
            # Update weights with LLM optimization
            self._allocator.update_weights(strategy_metrics)

            # Apply LLM-based capital optimization
            if self._capital_optimizer and strategy_metrics:
                try:
                    current_weights = {
                        s: self._allocator._weights.get(s, 0.0) for s in strategy_metrics.keys()
                    }
                    optimized_weights = self._capital_optimizer.optimize_allocation(
                        strategy_metrics=strategy_metrics,
                        current_weights=current_weights,
                    )
                    # Apply optimized weights (with limits to prevent sudden changes)
                    if optimized_weights:
                        logger.info(f"Capital optimizer suggested weights: {optimized_weights}")
                except Exception as e:
                    logger.debug(f"Capital optimization error: {e}")

        # Update killswitch with initial capital and rolling PF
        if self._killswitch:
            self._killswitch.set_initial_capital(self._accounting.initial_capital)
            # Get rolling PF from strategy metrics
            if strategy_metrics:
                # Use average PF across all strategies
                total_wins = sum(m.get("wins", 0) for m in strategy_metrics.values())
                total_losses = sum(m.get("losses", 0) for m in strategy_metrics.values())
                if total_losses > 0:
                    avg_pf = total_wins / total_losses
                elif total_wins > 0:
                    avg_pf = total_wins
                else:
                    avg_pf = 1.0
                self._killswitch.update_rolling_pf(avg_pf)

        # Update trade density metrics for all strategies
        for strategy in self._strategies:
            density_state = trade_density.get_density_state(strategy.strategy_id)
            metrics.set_gauge(
                f"trade_density_idle_days_{strategy.strategy_id}", density_state["idle_days"]
            )
            metrics.set_gauge(
                f"trade_density_relaxation_level_{strategy.strategy_id}",
                float(density_state["density_relaxation_level"]),
            )

        # Get current weights for display
        weights = self._allocator.get_weights()
        weights_str = ", ".join([f"{k}: {v:.1%}" for k, v in weights.items()])

        # Get profit target progress
        progress = self._profit_tracker.get_progress()

        # Check profit capture (if enabled)
        if self._profit_capture and self._profit_capture._enabled:
            try:
                await self._profit_capture.check_and_trigger(equity, self)
            except Exception as e:
                logger.debug(f"Profit capture check error: {e}")

        # Generate daily report (once per day)
        if self._report_generator:
            try:
                current_date = datetime.utcnow().date()
                if (
                    not hasattr(self, "_last_report_date")
                    or getattr(self, "_last_report_date", None) != current_date
                ):
                    strategy_metrics = self._accounting.get_strategy_metrics()
                    performance_data = {
                        "equity": snapshot.equity,
                        "drawdown_pct": snapshot.drawdown_pct,
                        "total_trades": sum(
                            m.get("trades", 0) for m in (strategy_metrics or {}).values()
                        ),
                    }
                    report = self._report_generator.generate_daily_report(
                        performance_data=performance_data,
                        strategy_metrics=strategy_metrics or {},
                    )
                    if report:
                        logger.info(
                            f"üìä Daily Report: PnL=${report['summary']['total_pnl']:.2f}, "
                            f"Best Strategy={report.get('best_strategy', {}).get('id', 'N/A')} "
                            f"(PF={report.get('best_strategy', {}).get('profit_factor', 0):.2f})"
                        )
                    self._last_report_date = current_date
            except Exception as e:
                logger.debug(f"Report generation error: {e}")

        print(
            f"[{snapshot.timestamp.strftime('%H:%M:%S')}] "
            f"Equity: ${snapshot.equity:,.2f} | "
            f"Daily PnL: ${snapshot.daily_pnl:,.2f} | "
            f"Profit: ${progress['current']:.2f}/${progress['target']:.2f} ({progress['progress_pct']:.1f}%) | "
            f"Trades: {int(progress['trades'])} | "
            f"Drawdown: {snapshot.drawdown_pct:.2f}% | "
            f"Positions: {len(self._accounting.get_positions())} | "
            f"Weights: {weights_str}"
        )

    async def run(self) -> None:
        """Run the trading system."""
        await self.start()
        try:
            while self._running:
                await asyncio.sleep(1)
        except KeyboardInterrupt:
            logger.info("Received interrupt signal")
        finally:
            await self.stop()


async def run_evaluation(days: int) -> dict[str, Any]:
    """Run readiness evaluation using TradingSystem.

    ARCHITECTURAL FIX: Previously, run_evaluation() created components
    independently, bypassing ExecutionRouter and TradingSystem's signal‚Üíorder‚Üífill
    pipeline. This resulted in zero trades and invalid metrics (PF=0, MaxDD=100%).

    Now, evaluation uses TradingSystem as the execution backbone, ensuring:
    - Signals are routed through risk limits
    - Orders are executed via ExecutionRouter
    - Fills update PortfolioAccounting
    - Same logic as run/backtest commands

    Returns:
        Evaluation result dictionary
    """
    from hean.evaluation.readiness import ReadinessEvaluator

    logger.info(f"[run_evaluation] Starting readiness evaluation for {days} days...")

    # Reset no-trade counters at the start of each evaluation run
    no_trade_report.reset()

    # Create EventSimulator as price feed
    start_date = datetime.utcnow() - timedelta(days=days)
    simulator = EventSimulator(None, ["BTCUSDT", "ETHUSDT"], start_date, days)
    # Note: EventSimulator will get bus from TradingSystem.start()

    # Create TradingSystem in evaluate mode
    system = TradingSystem(mode="evaluate")

    # Start system with EventSimulator as price feed
    await system.start(price_feed=simulator)

    logger.info("[run_evaluation] TradingSystem started, beginning simulation...")

    # Run simulation (EventSimulator will publish ticks)
    await simulator.run()

    logger.info("[run_evaluation] Simulation completed, processing remaining events...")

    # Give event bus time to process remaining events
    await asyncio.sleep(0.5)

    # Stop system
    await system.stop()

    logger.info("[run_evaluation] TradingSystem stopped, calculating metrics...")

    # Build metrics from TradingSystem's accounting
    # Get strategies dict for metrics
    strategies_dict: dict[str, BaseStrategy] = {}
    if system._impulse_engine:
        strategies_dict["impulse_engine"] = system._impulse_engine
    for strategy in system._strategies:
        if strategy.strategy_id not in strategies_dict:
            strategies_dict[strategy.strategy_id] = strategy

    # Get paper broker from execution router
    paper_broker = system._execution_router._paper_broker

    metrics_calc = BacktestMetrics(
        accounting=system._accounting,
        paper_broker=paper_broker,
        strategies=strategies_dict,
        allocator=system._allocator,
    )

    metrics = metrics_calc.calculate()

    # Check metrics and log warnings instead of raising errors
    total_trades = metrics.get("total_trades", 0)
    total_pnl = metrics.get("total_pnl", 0.0)
    profit_factor = metrics.get("profit_factor", 0.0)

    if total_trades < 5:
        logger.warning(
            f"[METRICS_WARNING] total_trades={total_trades} < 5. "
            f"Expected at least 5 trades in evaluation."
        )
    else:
        logger.info(f"[METRICS] total_trades={total_trades}")

    if total_pnl <= 0:
        logger.warning(
            f"[METRICS_WARNING] total_pnl={total_pnl:.2f} <= 0. "
            f"Expected positive PnL in evaluation."
        )
    else:
        logger.info(f"[METRICS] total_pnl={total_pnl:.2f}")

    if profit_factor <= 1.0:
        logger.warning(
            f"[METRICS_WARNING] profit_factor={profit_factor:.2f} <= 1.0. "
            f"Expected profit_factor > 1.0 in evaluation."
        )
    else:
        logger.info(f"[METRICS] profit_factor={profit_factor:.2f}")

    logger.info(
        f"[METRICS_SUMMARY] total_trades={total_trades}, "
        f"total_pnl={total_pnl:.2f}, profit_factor={profit_factor:.2f}"
    )

    # Evaluate readiness
    evaluator = ReadinessEvaluator()
    result = evaluator.evaluate(metrics)

    # Print readiness report
    logger.info("[run_evaluation] Printing readiness report...")
    evaluator.print_report(result)

    # Print no-trade / signal block summary
    summary = no_trade_report.get_summary()
    if summary.totals:
        logger.info("[no_trade] Evaluation no-trade totals: %s", summary.totals)
    if summary.per_strategy:
        logger.info("[no_trade] Evaluation no-trade per-strategy: %s", summary.per_strategy)

    # DEBUG: Print forced order flow metrics
    logger.info(
        f"[DEBUG_METRICS] signals_generated={system._signals_generated} "
        f"signals_after_filters={system._signals_after_filters} "
        f"orders_sent={system._orders_sent} "
        f"orders_filled={system._orders_filled}"
    )

    # Run truth layer / self-explanation using metrics, readiness result, and no-trade stats
    diagnosis = analyze_truth(metrics, summary, result)
    print_truth(diagnosis)

    logger.info("[run_evaluation] Evaluation completed")

    return {
        "passed": result.passed,
        "criteria": result.criteria,
        "recommendations": result.recommendations,
        "regime_results": result.regime_results,
    }


async def run_backtest(days: int, output_file: str | None = None) -> None:
    """Run a backtest.

    ARCHITECTURAL FIX: Now uses TradingSystem like evaluation to ensure
    signals go through the full pipeline (signal ‚Üí order ‚Üí fill) with
    proper tracing and retry queue support.
    """
    logger.info(f"[run_backtest] Starting backtest for {days} days...")

    # Enable debug mode for backtest to allow trades to execute
    original_debug_mode = settings.debug_mode
    settings.debug_mode = True
    logger.info("[run_backtest] Debug mode enabled for backtest")

    # Reset no-trade counters at the start of each backtest run
    no_trade_report.reset()

    # Create EventSimulator as price feed
    start_date = datetime.utcnow() - timedelta(days=days)
    simulator = EventSimulator(None, ["BTCUSDT", "ETHUSDT"], start_date, days)

    # Create TradingSystem (use "evaluate" mode to skip health check)
    system = TradingSystem(mode="evaluate")

    # Start system with EventSimulator as price feed
    await system.start(price_feed=simulator)
    logger.info("[run_backtest] TradingSystem started, beginning simulation...")

    # Run simulation (EventSimulator will publish ticks)
    await simulator.run()
    logger.info("[run_backtest] Simulation completed, processing remaining events...")

    # Process remaining events in batches
    max_batch_size = 10000  # Increased batch size for faster processing
    max_iterations = 5000  # Increased iterations to process more events
    total_processed = 0
    for iteration in range(max_iterations):
        queue_size = system._bus._queue.qsize()
        if queue_size == 0:
            logger.info(
                f"[run_backtest] Event queue empty after processing {total_processed} events"
            )
            break
        processed = await system._bus.flush(max_events=max_batch_size)
        total_processed += processed
        if processed == 0:
            # No events processed, wait a bit for async handlers to complete
            await asyncio.sleep(0.05)  # Reduced wait time
        if iteration % 50 == 0:
            logger.info(
                f"[run_backtest] Processing events... queue_size={queue_size}, processed={total_processed}"
            )
    if system._bus._queue.qsize() > 0:
        remaining = system._bus._queue.qsize()
        logger.warning(
            f"[run_backtest] Still {remaining} events in queue after processing {total_processed} events"
        )
        # Try to process a few more batches of remaining events
        for _ in range(100):
            if system._bus._queue.qsize() == 0:
                break
            await system._bus.flush(max_events=10000)
            await asyncio.sleep(0.01)
    logger.info("[run_backtest] Calculating metrics...")

    # Stop system
    await system.stop()

    # Build metrics from TradingSystem's accounting
    strategies_dict: dict[str, BaseStrategy] = {}
    if system._impulse_engine:
        strategies_dict["impulse_engine"] = system._impulse_engine
    for strategy in system._strategies:
        if strategy.strategy_id not in strategies_dict:
            strategies_dict[strategy.strategy_id] = strategy

    # Get paper broker from execution router
    paper_broker = system._execution_router._paper_broker

    # DEBUG: Check paper broker stats before calculating metrics
    if paper_broker:
        fill_stats = paper_broker.get_fill_stats()
        logger.info(f"[DEBUG_BACKTEST] Paper broker fill stats: {fill_stats}")

    metrics_calc = BacktestMetrics(
        accounting=system._accounting,
        paper_broker=paper_broker,
        strategies=strategies_dict,
        allocator=system._allocator,
        execution_router=system._execution_router,
    )

    metrics = metrics_calc.calculate()

    # DEBUG: Log calculated metrics
    logger.info(
        f"[DEBUG_BACKTEST] Calculated metrics: total_trades={metrics.get('total_trades', 0)}"
    )

    # Check metrics and log warnings instead of raising errors
    total_trades = metrics.get("total_trades", 0)
    total_pnl = metrics.get("total_pnl", 0.0)
    profit_factor = metrics.get("profit_factor", 0.0)

    if total_trades < 5:
        logger.warning(
            f"[METRICS_WARNING] total_trades={total_trades} < 5. "
            f"Expected at least 5 trades in backtest."
        )
    else:
        logger.info(f"[METRICS] total_trades={total_trades}")

    if total_pnl <= 0:
        logger.warning(
            f"[METRICS_WARNING] total_pnl={total_pnl:.2f} <= 0. "
            f"Expected positive PnL in backtest."
        )
    else:
        logger.info(f"[METRICS] total_pnl={total_pnl:.2f}")

    if profit_factor <= 1.0:
        logger.warning(
            f"[METRICS_WARNING] profit_factor={profit_factor:.2f} <= 1.0. "
            f"Expected profit_factor > 1.0 in backtest."
        )
    else:
        logger.info(f"[METRICS] profit_factor={profit_factor:.2f}")

    logger.info(
        f"[METRICS_SUMMARY] total_trades={total_trades}, "
        f"total_pnl={total_pnl:.2f}, profit_factor={profit_factor:.2f}"
    )

    logger.info("[run_backtest] Printing backtest report...")
    metrics_calc.print_report(metrics)

    # Print no-trade / signal block summary
    summary = no_trade_report.get_summary()
    if summary.totals:
        logger.info("[no_trade] Backtest no-trade totals: %s", summary.totals)
    if summary.per_strategy:
        logger.info("[no_trade] Backtest no-trade per-strategy: %s", summary.per_strategy)

    # DEBUG: Print forced order flow metrics
    logger.info(
        f"[DEBUG_METRICS] signals_generated={system._signals_generated} "
        f"signals_after_filters={system._signals_after_filters} "
        f"orders_sent={system._orders_sent} "
        f"orders_filled={system._orders_filled}"
    )

    # Save JSON if requested
    if output_file:
        logger.info(f"[run_backtest] Saving metrics to {output_file}...")
        metrics_calc.save_json(output_file)

    logger.info("[run_backtest] Backtest completed")

    # Restore original debug mode
    settings.debug_mode = original_debug_mode
    logger.info(f"[run_backtest] Debug mode restored to {original_debug_mode}")


def main() -> None:
    """Main entrypoint."""
    parser = argparse.ArgumentParser(description="HEAN Trading System")
    subparsers = parser.add_subparsers(dest="command", help="Command to run")

    subparsers.add_parser("run", help="Run the trading system")
    subparsers.add_parser("report", help="Show trading diagnostics report (attempts, blocks, reasons)")
    backtest_parser = subparsers.add_parser("backtest", help="Run a backtest")
    backtest_parser.add_argument("--days", type=int, default=30, help="Number of days to backtest")
    backtest_parser.add_argument(
        "--out", type=str, default=None, help="Output JSON report file path"
    )

    evaluate_parser = subparsers.add_parser("evaluate", help="Evaluate system readiness")
    evaluate_parser.add_argument("--days", type=int, default=60, help="Number of days to evaluate")

    # Process Factory commands (experimental)
    process_parser = subparsers.add_parser("process", help="Process Factory commands (experimental)")
    process_subparsers = process_parser.add_subparsers(dest="process_command", help="Process Factory command")

    process_subparsers.add_parser(
        "scan",
        help="Scan environment and create snapshot. Prints snapshot ID and staleness warnings.",
    )
    process_plan_parser = process_subparsers.add_parser(
        "plan",
        help="Plan daily capital allocation. Prints top opportunities, capital plan, and selection rationale.",
    )
    process_plan_parser.add_argument(
        "--capital", type=float, default=400.0, help="Total capital in USD"
    )
    process_run_parser = process_subparsers.add_parser(
        "run",
        help="Run a process. Prints net contribution and kill/scale suggestions.",
    )
    process_run_parser.add_argument(
        "--process-id", type=str, required=True, help="Process ID to run"
    )
    process_run_parser.add_argument(
        "--mode",
        type=str,
        default="sandbox",
        choices=["sandbox", "live"],
        help="Execution mode",
    )
    process_run_parser.add_argument(
        "--capital", type=float, default=0.0, help="Capital allocated in USD"
    )
    process_run_parser.add_argument(
        "--force",
        action="store_true",
        help="Force run even if daily_run_key exists (bypass idempotency)",
    )
    process_subparsers.add_parser(
        "report",
        help="Generate daily report. Includes top contributors (net), profit illusion list, portfolio health score.",
    )
    process_evaluate_parser = process_subparsers.add_parser(
        "evaluate",
        help="Evaluate portfolio over date range. Replays stored runs and prints stable metrics.",
    )
    process_evaluate_parser.add_argument(
        "--days", type=int, default=30, help="Number of days to look back (default 30)"
    )
    process_subparsers.add_parser(
        "exec-smoke-test",
        help="Run execution smoke test (place and cancel a small test order)",
    )

    args = parser.parse_args()

    # Setup logging
    setup_logging()

    # Validate configuration
    if settings.trading_mode == "live" and not settings.is_live:
        logger.error("Live trading requires LIVE_CONFIRM=YES")
        sys.exit(1)

    if args.command == "run":
        system = TradingSystem()
        # Create a fresh event loop explicitly.  asyncio.get_event_loop() is
        # deprecated in Python 3.10+ (and raises DeprecationWarning / RuntimeError
        # in 3.12+) when called at the top level without a current loop set.
        # asyncio.new_event_loop() + set_event_loop() is the correct pattern.
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        # Handle signals for graceful shutdown
        def signal_handler(sig, frame):
            sig_name = "SIGINT" if sig == signal.SIGINT else "SIGTERM"
            logger.critical(f"Received {sig_name}, initiating graceful shutdown...")

            # Create async shutdown task
            async def graceful_shutdown():
                try:
                    # Panic close all positions first
                    logger.critical("EMERGENCY: Closing all positions...")
                    close_result = await system.panic_close_all(reason=f"graceful_shutdown_{sig_name}")
                    logger.critical(
                        f"Panic close complete: closed={close_result.get('positions_closed', 0)}, "
                        f"cancelled={close_result.get('orders_cancelled', 0)}"
                    )

                    # Stop the trading system
                    logger.info("Stopping trading system...")
                    await system.stop()
                    logger.info("Trading system stopped gracefully")

                except Exception as e:
                    logger.error(f"Error during graceful shutdown: {e}", exc_info=True)
                finally:
                    # Stop the event loop
                    loop.stop()

            # Schedule graceful shutdown
            loop.create_task(graceful_shutdown())

        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)
        logger.info("Signal handlers installed for graceful shutdown")

        try:
            loop.run_until_complete(system.run())
        except KeyboardInterrupt:
            pass
        finally:
            loop.close()

    elif args.command == "report":
        # Show trading diagnostics report
        from hean.observability.no_trade_report import no_trade_report

        summary = no_trade_report.get_summary()

        print("=" * 70)
        print("üìä TRADING DIAGNOSTICS REPORT")
        print("=" * 70)
        print()

        # Pipeline counters
        pipeline = summary.pipeline_counters
        print("üìà PIPELINE COUNTERS:")
        print(f"  Signals emitted: {pipeline.get('signals_emitted', 0)}")
        print(f"  Orders created: {pipeline.get('orders_created', 0)}")
        print(f"  Positions opened: {pipeline.get('positions_opened', 0)}")
        print(f"  Positions closed: {pipeline.get('positions_closed', 0)}")
        print()

        # Block reasons
        totals = summary.totals
        if totals:
            print("üö´ BLOCK REASONS (Total):")
            sorted_reasons = sorted(totals.items(), key=lambda x: x[1], reverse=True)
            for reason, count in sorted_reasons[:10]:  # Top 10
                print(f"  {reason}: {count}")
            print()

        # Per strategy
        per_strategy = summary.per_strategy
        if per_strategy:
            print("üìä PER STRATEGY:")
            for strategy_id, reasons in per_strategy.items():
                total = sum(reasons.values())
                if total > 0:
                    print(f"  {strategy_id}: {total} blocks")
                    top_reasons = sorted(reasons.items(), key=lambda x: x[1], reverse=True)[:3]
                    for reason, count in top_reasons:
                        print(f"    - {reason}: {count}")
            print()

        # Per symbol
        per_symbol = summary.per_symbol
        if per_symbol:
            print("üìä PER SYMBOL:")
            for symbol, reasons in per_symbol.items():
                total = sum(reasons.values())
                if total > 0:
                    print(f"  {symbol}: {total} blocks")
                    top_reasons = sorted(reasons.items(), key=lambda x: x[1], reverse=True)[:3]
                    for reason, count in top_reasons:
                        print(f"    - {reason}: {count}")
            print()

        # Paper assist status
        from hean.paper_trade_assist import is_paper_assist_enabled
        if is_paper_assist_enabled():
            print("‚úÖ PAPER_TRADE_ASSIST: ENABLED")
            print(f"  Micro-trade interval: {settings.paper_trade_assist_micro_trade_interval_sec}s")
            print(f"  Micro-trade notional: ${settings.paper_trade_assist_micro_trade_notional_usd}")
            print()

        print("=" * 70)

    elif args.command == "backtest":
        asyncio.run(run_backtest(args.days, args.out))

    elif args.command == "evaluate":
        result = asyncio.run(run_evaluation(args.days))
        # Exit with code 0 if passed, 1 if failed
        sys.exit(0 if result["passed"] else 1)

    elif args.command == "process":
        # Process Factory commands (experimental)
        if not settings.process_factory_enabled:
            logger.error(
                "Process Factory is disabled. Enable it in config with process_factory_enabled=true"
            )
            sys.exit(1)

        from hean.process_factory.engine import ProcessEngine
        from hean.process_factory.report import ProcessReportGenerator
        from hean.process_factory.storage import SQLiteStorage

        storage = SQLiteStorage("process_factory.db")
        engine = ProcessEngine(storage)

        try:
            if args.process_command == "scan":
                async def scan_with_output():
                    snapshot = await engine.scan_environment()
                    print("\n‚úì Environment scan completed")
                    print(f"  Snapshot ID: {snapshot.snapshot_id}")
                    print(f"  Timestamp: {snapshot.timestamp.isoformat()}")
                    if snapshot.is_stale():
                        print(f"  ‚ö† WARNING: Snapshot is stale ({snapshot.staleness_hours:.1f} hours old)")
                    else:
                        print(f"  ‚úì Snapshot is fresh ({snapshot.staleness_hours:.1f} hours old)")
                    print(f"  Balances: {len(snapshot.balances)} assets")
                    print(f"  Positions: {len(snapshot.positions)}")
                    print(f"  Funding rates: {len(snapshot.funding_rates)} symbols")
                    return snapshot
                asyncio.run(scan_with_output())

            elif args.process_command == "plan":
                async def plan_with_output():
                    ranked, plan = await engine.plan(args.capital)
                    print(f"\n‚úì Planning completed: {len(ranked)} opportunities")
                    print("\nüìä Capital Plan:")
                    print(f"  Reserve: ${plan.reserve_usd:.2f} ({plan.reserve_usd/plan.total_capital_usd*100:.1f}%)")
                    print(f"  Active: ${plan.active_usd:.2f} ({plan.active_usd/plan.total_capital_usd*100:.1f}%)")
                    print(f"  Experimental: ${plan.experimental_usd:.2f} ({plan.experimental_usd/plan.total_capital_usd*100:.1f}%)")
                    print("\nüéØ Top Opportunities:")
                    for i, (opp, _score) in enumerate(ranked[:5], 1):
                        print(f"  {i}. {opp.id}: ${opp.expected_profit_usd:.2f} profit, {opp.time_hours:.1f}h, risk={opp.risk_factor:.1f}")
                    print("\nüí∞ Allocations:")
                    for process_id, allocation in sorted(plan.allocations.items(), key=lambda x: x[1], reverse=True):
                        print(f"  {process_id}: ${allocation:.2f}")
                    return ranked, plan
                asyncio.run(plan_with_output())

            elif args.process_command == "run":
                async def run_with_output():
                    try:
                        run = await engine.run_process(
                            args.process_id, {}, args.mode, args.capital, force=args.force
                        )
                    except ValueError as e:
                        if "stale" in str(e).lower():
                            print(f"\n‚ùå {e}")
                            sys.exit(1)
                        raise
                    from hean.process_factory.truth_layer import TruthLayer
                    truth_layer = TruthLayer()
                    attribution = truth_layer.compute_attribution(run)

                    print(f"\n‚úì Process run completed: {run.run_id}")
                    print(f"  Status: {run.status.value}")
                    print(f"  Process: {run.process_id}")
                    print(f"  Mode: {args.mode}")
                    print("\nüìä Attribution:")
                    print(f"  Gross PnL: ${attribution.gross_pnl_usd:.2f}")
                    print(f"  Net PnL: ${attribution.net_pnl_usd:.2f}")
                    print(f"  Fees: ${attribution.total_fees_usd:.2f}")
                    print(f"  Funding: ${attribution.total_funding_usd:.2f}")
                    print(f"  Rewards: ${attribution.total_rewards_usd:.2f}")
                    print(f"  Opportunity Cost: ${attribution.opportunity_cost_usd:.2f}")
                    if attribution.profit_illusion:
                        print("  ‚ö† Profit Illusion: Gross positive but net negative!")

                    # Get kill/scale suggestions
                    portfolio = await engine.update_portfolio()
                    entry = next((e for e in portfolio if e.process_id == run.process_id), None)
                    if entry:
                        print("\nüí° Recommendations:")
                        if entry.state.value == "KILLED":
                            print("  ‚ùå Process is KILLED")
                        elif entry.fail_rate > 0.7:
                            print(f"  ‚ö† High fail rate ({entry.fail_rate:.1%}), consider killing")
                        elif entry.runs_count >= 5 and entry.avg_roi > 0 and entry.fail_rate < 0.4:
                            print("  ‚úì Good performance, eligible for scaling")
                        else:
                            print(f"  ‚Üí Continue testing ({entry.runs_count} runs)")

                    if run.error:
                        print(f"\n‚ùå Error: {run.error}")
                    return run
                asyncio.run(run_with_output())

            elif args.process_command == "report":
                async def generate_report():
                    portfolio = await engine.update_portfolio()
                    capital_plan = await storage.load_latest_capital_plan()
                    recent_runs = await storage.list_runs(limit=50)

                    # Compute attribution for profit illusion detection
                    from hean.process_factory.truth_layer import TruthLayer
                    truth_layer = TruthLayer()
                    attributions = truth_layer.compute_portfolio_attribution(recent_runs)

                    generator = ProcessReportGenerator()
                    result = generator.generate_daily_report(
                        portfolio, capital_plan, recent_runs
                    )

                    if result is None:
                        # Idempotent: report already exists
                        date_str = datetime.now().strftime("%Y-%m-%d")
                        md_path = generator.output_dir / f"process_factory_report_{date_str}.md"
                        json_path = generator.output_dir / f"process_factory_report_{date_str}.json"
                        print("\n‚úì Report already exists (idempotent skip):")
                        print(f"  Markdown: {md_path}")
                        print(f"  JSON: {json_path}")
                        return None, None

                    md_path, json_path = result
                    print("\n‚úì Report generated:")
                    print(f"  Markdown: {md_path}")
                    print(f"  JSON: {json_path}")

                    # Print summary
                    print("\nüìä Portfolio Summary:")
                    total_net = sum(a.net_pnl_usd for a in attributions.values())
                    total_gross = sum(a.gross_pnl_usd for a in attributions.values())
                    profit_illusion_count = sum(1 for a in attributions.values() if a.profit_illusion)
                    print(f"  Total Net Contribution: ${total_net:.2f}")
                    print(f"  Total Gross PnL: ${total_gross:.2f}")
                    print(f"  Profit Illusion Processes: {profit_illusion_count}")

                    # Top contributors (net)
                    sorted_attributions = sorted(
                        attributions.items(), key=lambda x: x[1].net_pnl_usd, reverse=True
                    )[:5]
                    print("\nüèÜ Top Contributors (Net):")
                    for process_id, attr in sorted_attributions:
                        if attr.net_pnl_usd > 0:
                            print(f"  {process_id}: ${attr.net_pnl_usd:.2f} net")

                    # Profit illusion list
                    if profit_illusion_count > 0:
                        print("\n‚ö† Profit Illusion Processes:")
                        for process_id, attr in attributions.items():
                            if attr.profit_illusion:
                                print(f"  {process_id}: ${attr.gross_pnl_usd:.2f} gross ‚Üí ${attr.net_pnl_usd:.2f} net")

                    # Portfolio health
                    from hean.process_factory.evaluation import PortfolioEvaluator
                    evaluator = PortfolioEvaluator(storage)
                    health_score, _ = await evaluator.evaluate_portfolio(days=30)
                    print("\nüíö Portfolio Health Score:")
                    print(f"  Stability: {health_score.stability_score:.2%}")
                    print(f"  Concentration Risk: {health_score.concentration_risk:.2%}")
                    print(f"  Churn Rate: {health_score.churn_rate:.2f}")
                    print(f"  Core Processes: {health_score.core_process_count}")
                    print(f"  Testing Processes: {health_score.testing_process_count}")
                    print(f"  Killed Processes: {health_score.killed_process_count}")

                    return md_path, json_path

                asyncio.run(generate_report())

            elif args.process_command == "evaluate":
                async def evaluate_with_output():
                    from hean.process_factory.evaluation import PortfolioEvaluator
                    evaluator = PortfolioEvaluator(storage)
                    health_score, process_results = await evaluator.evaluate_portfolio(
                        days=args.days
                    )

                    print(f"\n‚úì Portfolio Evaluation ({args.days} days)")
                    print("\nüíö Portfolio Health Score:")
                    print(f"  Stability: {health_score.stability_score:.2%}")
                    print(f"  Concentration Risk: {health_score.concentration_risk:.2%}")
                    print(f"  Churn Rate: {health_score.churn_rate:.2f}")
                    print(f"  Net Contribution: ${health_score.net_contribution_usd:.2f}")
                    print(f"  Profit Illusion Count: {health_score.profit_illusion_count}")
                    print(f"  Core: {health_score.core_process_count}, Testing: {health_score.testing_process_count}, Killed: {health_score.killed_process_count}")

                    print("\nüìã Process Recommendations:")
                    for result in sorted(process_results, key=lambda x: x.net_contribution_usd, reverse=True):
                        print(f"\n  {result.process_id}:")
                        print(f"    Recommendation: {result.recommendation}")
                        print(f"    Net Contribution: ${result.net_contribution_usd:.2f}")
                        print(f"    Runs: {result.runs_count}, Win Rate: {result.win_rate:.1%}, Stability: {result.stability:.1%}")
                        if result.reasons:
                            print(f"    Reasons: {', '.join(result.reasons)}")

                    return health_score, process_results

                asyncio.run(evaluate_with_output())

            elif args.process_command == "exec-smoke-test":
                from hean.process_factory.integrations.smoke_test import run_smoke_test

                async def smoke_test_with_output():
                    try:
                        result = await run_smoke_test()
                    except ValueError as e:
                        print(f"\n‚ùå Validation error: {e}")
                        sys.exit(1)

                    if result["success"]:
                        print("\n‚úì SUCCESS: Execution smoke test passed")
                        print(f"  Order ID: {result['order_id']}")
                        print(f"  Symbol: {result['symbol']}")
                        print(f"  Side: {result['side']}")
                        print(f"  Quantity: {result['qty']:.6f}")
                        print(f"  Price: ${result['price']:.2f}")
                        print("\n  Order placed and cancelled successfully.")
                    else:
                        print("\n‚ùå FAIL: Execution smoke test failed")
                        print(f"  Error type: {result.get('error_type', 'unknown')}")
                        print(f"  Error: {result.get('error', 'unknown error')}")
                        print("\n  Suggested fixes:")
                        if result.get('error_type') == 'not_enabled':
                            print("    - Set PROCESS_FACTORY_ALLOW_ACTIONS=true")
                            print("    - Set DRY_RUN=false")
                        elif result.get('error_type') == 'min_notional':
                            print(f"    - Increase EXECUTION_SMOKE_TEST_NOTIONAL_USD (min ${result.get('error', '').split()[-1] if '$' in result.get('error', '') else '5'})")
                        elif result.get('error_type') == 'validation_error':
                            print("    - Check configuration flags")
                        else:
                            print("    - Check API credentials (BYBIT_API_KEY, BYBIT_API_SECRET)")
                            print("    - Check network connectivity")
                            print(f"    - Verify symbol is valid: {result.get('symbol', 'unknown')}")
                        sys.exit(1)

                    return result

                asyncio.run(smoke_test_with_output())

            else:
                process_parser.print_help()
                sys.exit(1)

        finally:
            asyncio.run(storage.close())

    else:
        parser.print_help()
        sys.exit(1)


if __name__ == "__main__":
    main()
